{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 2576183S RecSys 2021M - Ex2 TEMPLATE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inwi1o3992TW"
      },
      "source": [
        "# Exerise 2\n",
        "\n",
        "The aims of this execise are to:\n",
        " - Make your first recommender by implementing a user-based CF (c.f. Lecture 4).\n",
        " - Make your first recommendations using Spotlight recommender toolkit on explicit data (Lecture 8)\n",
        " - Develop and evaluate baseline recommender systems (c.f. Lecture 3)\n",
        " - Start to think about explicit vs implicit learners\n",
        " - Evaluate your results using Spotlight (Lecture 6 & 7)\n",
        "\n",
        "This exercise builds on the lectures' material, namely Lectures 3, 4, 6, 7 and 8.\n",
        "\n",
        "There are 10 tasks to increase your understanding of the content of the Recommender Sytems course.  Each of these tasks have corresponding questions in the quiz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys992pU79yhD"
      },
      "source": [
        "#Standard setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from typing import List, Tuple, Sequence\n",
        "SEED=20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Vlbi9W-d2j"
      },
      "source": [
        "We'll be using Movielens again. Let's load it in to the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg093kVRAvHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3cc6ad-7ff0-43e8-ccfe-fdaa59c2a1b9"
      },
      "source": [
        "!curl -o ml-latest-small.zip http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "# backup location\n",
        "#!curl -o ml-latest-small.zip http://www.dcs.gla.ac.uk/~craigm/recsysHM/ml-latest-small.zip\n",
        "!unzip -o ml-latest-small.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  955k  100  955k    0     0   891k      0  0:00:01  0:00:01 --:--:--  891k\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yss68U_EA0w2"
      },
      "source": [
        "ratings_df = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
        "movies_df = pd.read_csv(\"ml-latest-small/movies.csv\")\n",
        "\n",
        "# we're going to treat userId as strings, and similarly as movies. This will prevent confusion later on.\n",
        "ratings_df['userId'] =  \"u\" + ratings_df['userId'].astype(str)\n",
        "ratings_df['movieId'] = \"m\" + ratings_df['movieId'].astype(str)\n",
        "movies_df['movieId'] = \"m\" +  movies_df['movieId'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5QQBZ3QS2Hv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7b3897ab-4e39-44e9-db1a-b2adde2bf0b7"
      },
      "source": [
        "ratings_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u1</td>\n",
              "      <td>m1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u1</td>\n",
              "      <td>m3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u1</td>\n",
              "      <td>m6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u1</td>\n",
              "      <td>m47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u1</td>\n",
              "      <td>m50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  userId movieId  rating  timestamp\n",
              "0     u1      m1     4.0  964982703\n",
              "1     u1      m3     4.0  964981247\n",
              "2     u1      m6     4.0  964982224\n",
              "3     u1     m47     5.0  964983815\n",
              "4     u1     m50     5.0  964982931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMfsveWjS4xP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2062b8df-6fa3-4343-b38f-ab7180e5123c"
      },
      "source": [
        "\n",
        "movies_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>m1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>m2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>m3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>m4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>m5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  movieId  ...                                       genres\n",
              "0      m1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
              "1      m2  ...                   Adventure|Children|Fantasy\n",
              "2      m3  ...                               Comedy|Romance\n",
              "3      m4  ...                         Comedy|Drama|Romance\n",
              "4      m5  ...                                       Comedy\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rAIXwDoBCda"
      },
      "source": [
        "# Part A. User-based CF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isjp_rS0BCgh"
      },
      "source": [
        "You can generate a matrix of ratings with the ratings_df dataframe. In the matrix, the unrated items are filled with 0 (this means they have no impact upon the calculated Cosine value)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKsmW549BNlq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "dac4f32f-59c5-4789-96cf-38018e32b342"
      },
      "source": [
        "r_df_matrix = ratings_df.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "r_df_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>movieId</th>\n",
              "      <th>m1</th>\n",
              "      <th>m10</th>\n",
              "      <th>m100</th>\n",
              "      <th>m100044</th>\n",
              "      <th>m100068</th>\n",
              "      <th>m100083</th>\n",
              "      <th>m100106</th>\n",
              "      <th>m100159</th>\n",
              "      <th>m100163</th>\n",
              "      <th>m100194</th>\n",
              "      <th>m100226</th>\n",
              "      <th>m100277</th>\n",
              "      <th>m1003</th>\n",
              "      <th>m100302</th>\n",
              "      <th>m100304</th>\n",
              "      <th>m100306</th>\n",
              "      <th>m100326</th>\n",
              "      <th>m100383</th>\n",
              "      <th>m100390</th>\n",
              "      <th>m100397</th>\n",
              "      <th>m1004</th>\n",
              "      <th>m100487</th>\n",
              "      <th>m100498</th>\n",
              "      <th>m1005</th>\n",
              "      <th>m100507</th>\n",
              "      <th>m100527</th>\n",
              "      <th>m100553</th>\n",
              "      <th>m100556</th>\n",
              "      <th>m100579</th>\n",
              "      <th>m1006</th>\n",
              "      <th>m100611</th>\n",
              "      <th>m1007</th>\n",
              "      <th>m100714</th>\n",
              "      <th>m100737</th>\n",
              "      <th>m1008</th>\n",
              "      <th>m100810</th>\n",
              "      <th>m100843</th>\n",
              "      <th>m100882</th>\n",
              "      <th>m1009</th>\n",
              "      <th>m100906</th>\n",
              "      <th>...</th>\n",
              "      <th>m98836</th>\n",
              "      <th>m98908</th>\n",
              "      <th>m98961</th>\n",
              "      <th>m99</th>\n",
              "      <th>m990</th>\n",
              "      <th>m99005</th>\n",
              "      <th>m99007</th>\n",
              "      <th>m99030</th>\n",
              "      <th>m99087</th>\n",
              "      <th>m991</th>\n",
              "      <th>m99106</th>\n",
              "      <th>m99112</th>\n",
              "      <th>m99114</th>\n",
              "      <th>m99117</th>\n",
              "      <th>m99122</th>\n",
              "      <th>m99130</th>\n",
              "      <th>m99145</th>\n",
              "      <th>m99149</th>\n",
              "      <th>m99191</th>\n",
              "      <th>m993</th>\n",
              "      <th>m994</th>\n",
              "      <th>m99415</th>\n",
              "      <th>m99437</th>\n",
              "      <th>m99532</th>\n",
              "      <th>m99574</th>\n",
              "      <th>m996</th>\n",
              "      <th>m99636</th>\n",
              "      <th>m99638</th>\n",
              "      <th>m99721</th>\n",
              "      <th>m99728</th>\n",
              "      <th>m99750</th>\n",
              "      <th>m99764</th>\n",
              "      <th>m998</th>\n",
              "      <th>m99813</th>\n",
              "      <th>m99846</th>\n",
              "      <th>m99853</th>\n",
              "      <th>m999</th>\n",
              "      <th>m99910</th>\n",
              "      <th>m99917</th>\n",
              "      <th>m99992</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>u1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u100</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u101</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u102</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u95</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u96</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u97</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u98</th>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u99</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>610 rows  9724 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "movieId   m1  m10  m100  m100044  m100068  ...  m99853  m999  m99910  m99917  m99992\n",
              "userId                                     ...                                      \n",
              "u1       4.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u10      0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u100     0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u101     0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u102     0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "...      ...  ...   ...      ...      ...  ...     ...   ...     ...     ...     ...\n",
              "u95      0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u96      5.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u97      0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u98      4.5  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u99      0.0  4.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "\n",
              "[610 rows x 9724 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpJXEqQ_BKxg"
      },
      "source": [
        "The left hand bold column is the [index of the dataframe](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html) - that is, an attribute of the dataframe that allows fast lookup of rows. In this case, userId has become our index column.\n",
        "\n",
        "You can get all the index of users using the .index "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRIXYwQgBRt2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f666be-79a3-4464-cf00-7e425845c99f"
      },
      "source": [
        "r_df_matrix.index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['u1', 'u10', 'u100', 'u101', 'u102', 'u103', 'u104', 'u105', 'u106',\n",
              "       'u107',\n",
              "       ...\n",
              "       'u90', 'u91', 'u92', 'u93', 'u94', 'u95', 'u96', 'u97', 'u98', 'u99'],\n",
              "      dtype='object', name='userId', length=610)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8RcZo1bBU8O"
      },
      "source": [
        "You can also use [.loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) to access rows, by their \"index\". For instance, we can get all ratings of a specific user with userId=1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77XOSOdqBXmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6e0c39-5520-460d-ad7f-e3df050bd9e1"
      },
      "source": [
        "r_df_matrix.loc['u1']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "movieId\n",
              "m1         4.0\n",
              "m10        0.0\n",
              "m100       0.0\n",
              "m100044    0.0\n",
              "m100068    0.0\n",
              "          ... \n",
              "m99853     0.0\n",
              "m999       0.0\n",
              "m99910     0.0\n",
              "m99917     0.0\n",
              "m99992     0.0\n",
              "Name: u1, Length: 9724, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt9_SlC4Beut"
      },
      "source": [
        "User-based CF heavily relies upon Cosine similarity. We are providing a Cosine similarity implementation based on numpy operations. We also show how to use df.loc to get all the ratings of a given user from `r_df_matrix` as a Series - we then make this into a numpy array using the [.values](https://pandas.pydata.org/docs/reference/api/pandas.Series.values.html) property.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NXXbCQsBbJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb752d0-07eb-4e4c-f50f-18e6a84ef814"
      },
      "source": [
        "def cos_sim(a, b):\n",
        "  from numpy.linalg import norm\n",
        "  from numpy import dot\n",
        "  return dot(a, b)/(norm(a)*norm(b))\n",
        "\n",
        "print('Cosine similarity between userId=1 and itself is:')\n",
        "print(cos_sim(r_df_matrix.loc['u1'].values, r_df_matrix.loc['u1'].values))\n",
        "\n",
        "print('Cosine similarity between userId=1 and userId=607 is:')\n",
        "print(cos_sim(r_df_matrix.loc['u1'].values, r_df_matrix.loc['u607'].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity between userId=1 and itself is:\n",
            "1.0\n",
            "Cosine similarity between userId=1 and userId=607 is:\n",
            "0.2693892401115333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B061AiTiBlWJ"
      },
      "source": [
        "## Task 1. Get the most similar users.\n",
        "\n",
        "User-based CF is based on user-neighbourhoods. In this task, you will implement a function ` get_most_similar_users(userId : str, k : int = 10)` that will identify the userIds of the k most similar users to the specified userId, and their corresponding cosine similarities. \n",
        "\n",
        "In determining the most similar users, you should break ties based on their position in the array - for instance, if two users are tied as 2nd most similar user, the user who appears earlier should be 2nd, and the latter user third.\n",
        "\n",
        "You should exclude the compared user itself when generating a list of the most similar users.\n",
        "\n",
        "NB: We are using Python type hints to remind you what the function parameters (`str`, `int`) and return type (`Tuple[Sequence[str], Sequence[float]]`) should be.\n",
        "\n",
        "Hints: \n",
        " - The cos_sim function should be used here. \n",
        " - Higher cos_sim means more similar.\n",
        " - Try SciPy's [`rankdata()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html) function. Given an array, `rankdata()` tells you positions in sorted rank order. For instance:\n",
        "```\n",
        ">>> rankdata([5.9, 2.1, 4.3])\n",
        "array([3., 1., 2.])\n",
        "```\n",
        "It also has support for addressing ties.\n",
        " - The first return component of [np.nonzero](https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html) can be used to return the indices of the elements that are non-zero. E.g.\n",
        " ```\n",
        " >>> np.array([True,False]).nonzero()[0]\n",
        "array([0])\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWSQl5re9BgH"
      },
      "source": [
        "# from scipy.stats import rankdata\n",
        "# k = 4\n",
        "# cosine_values = []\n",
        "# similar_uids = []\n",
        "# for i in range(0, len(r_df_matrix.index)):\n",
        "#   a = r_df_matrix.index[i]\n",
        "#   uids.append(a)\n",
        "#   b = round(cos_sim(r_df_matrix.loc['u10'].values, r_df_matrix.loc[a].values),2)\n",
        "#   cosine_values.append(b)\n",
        "# # print(cosine_values)\n",
        "# # print(uids)\n",
        "# # print(rankdata(cosine_values))\n",
        "# index = rankdata(cosine_values).argsort()[-k:][::-1]\n",
        "\n",
        "# for i in range(0,len(index)):\n",
        "#   print(uids[index[i]], cosine_values[index[i]])\n",
        "# print(cosine_values)\n",
        "\n",
        "\n",
        "# index_of_non_zero_cosine_values = np.array(cosine_values).nonzero()\n",
        "\n",
        "# l = []\n",
        "# for i in index_of_non_zero_cosine_values[0]:\n",
        "#    l.append(cosine_values[i])\n",
        "# print(len(l))\n",
        "# print(len(index_of_non_zero_cosine_values[0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj1wpnS7BbMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5b9fba-ea6b-4d85-ddff-0571d2e57b41"
      },
      "source": [
        "from scipy.stats import rankdata\n",
        "\n",
        "def get_most_similar_users(userId : str, k : int = 10) -> Tuple[Sequence[str], Sequence[float]]:\n",
        "  # Add your solution here \n",
        "  cosine_values = []\n",
        "  similar_uids = []\n",
        "\n",
        "  #calculating cosine similarity between userId and all other userids\n",
        "  for i in range(0, len(r_df_matrix.index)):\n",
        "    a = r_df_matrix.index[i]\n",
        "    similar_uids.append(a)\n",
        "    b = cos_sim(r_df_matrix.loc[userId].values, r_df_matrix.loc[a].values)\n",
        "    cosine_values.append(b)\n",
        "  \n",
        "  #finding indices k most highest cosine values\n",
        "  K = k+1\n",
        "  rank_index = rankdata(cosine_values).argsort()[-K:][::-1]\n",
        "\n",
        "  topk_userids = [] # a list/numpy array of k userIds of top-k users\n",
        "  topk_cosines = []  # a list/numpy array of k cosine similarity values\n",
        "  \n",
        "  #based on indices, extracting userids and cosine values\n",
        "  for i in range(1,len(rank_index)):\n",
        "    topk_userids.append(similar_uids[rank_index[i]])\n",
        "    topk_cosines.append(cosine_values[rank_index[i]])\n",
        " \n",
        "  return (topk_userids, topk_cosines)\n",
        "\n",
        "print(get_most_similar_users(userId='u3', k=1))\n",
        "\n",
        "# Add your solution here (cosine similarity > 0)\n",
        "\n",
        "def non_zero_ratings(userId):\n",
        "  index_of_non_zero_ratings = np.array(r_df_matrix.loc[userId]).nonzero()\n",
        "  l = []\n",
        "  for i in index_of_non_zero_ratings[0]:\n",
        "    l.append(r_df_matrix.loc[userId][i])\n",
        "  return l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['u313'], [0.07818732282993371])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3jnW2BCAIWR"
      },
      "source": [
        "You can now answer the questions corresponding to Task 1 in the quiz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVnsPTKjzqnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a99c33a-273d-47ee-b1c0-358ec3a0204c"
      },
      "source": [
        "print(get_most_similar_users(userId='u10', k=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['u159'], [0.28826463078187997])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIMwvzqJ2YuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c051351e-95a4-42dd-87eb-99c9f7d5309d"
      },
      "source": [
        "print(get_most_similar_users(userId='u500', k=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['u453', 'u45'], [0.27983214052930266, 0.26236874974336444])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9ZepSCnBwc7"
      },
      "source": [
        "## Task 2. Predict ratings via user-based CF.\n",
        "\n",
        "Now you should implement your user-based CF, within a predict() function. \n",
        "The aim of this function is to predict the rating of a given userId for a given itemId.\n",
        "\n",
        "Your implementation should make use of your `get_most_similar_users()` implementation above, using k=10 nearest neighbours.\n",
        "\n",
        "Hint: \n",
        " - You may wish to revise user-based CF from Lecture 4. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DEsFvIASPpD"
      },
      "source": [
        "# top_userIds, top_cosines = get_most_similar_users('u1')\n",
        "# d = np.sum(top_cosines)\n",
        "# a = 0\n",
        "# l= []\n",
        "# for i in top_userIds:\n",
        "#   l.append(r_df_matrix.loc[i]['m1'] * top_cosines[a])\n",
        "#   a = a+1\n",
        "# print(np.sum(l)/d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eX33RkTBbS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d1009a3-26b9-442c-beb7-1be58ea9d143"
      },
      "source": [
        "def predict_rating(userId : str, movieId : str) -> float:\n",
        "  # add your solution here\n",
        "  top_userIds, top_cosines = get_most_similar_users(userId)\n",
        "  a = 0\n",
        "  l= []\n",
        "\n",
        "  #calculating ratings\n",
        "  for i in top_userIds:\n",
        "    l.append(r_df_matrix.loc[i][movieId] * top_cosines[a])\n",
        "    a = a+1\n",
        "\n",
        "  #using the formula of predict\n",
        "  predicted = round(np.sum(l)/np.sum(top_cosines),2) # predicted rating value\n",
        "  return predicted\n",
        "\n",
        "print(\"Predicted rating:\", predict_rating(userId='u1', movieId='m1'))\n",
        "\n",
        "print(\"Actual rating:\", r_df_matrix.loc['u1']['m1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted rating: 2.34\n",
            "Actual rating: 4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuWLuAZzB9br"
      },
      "source": [
        "You can complete answering the quiz questions for Task 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqfUghVsCA7G"
      },
      "source": [
        "## Task 3. Predict ratings via user-based CF with Mean-center normalisation.\n",
        "\n",
        "Users usually rate differently: (1) some rate high, while others low. (2) Some use more of the scale than others. However, the user-based CF we implemented above ignores these differences. To this end, we can apply normalisation to compensate. In this task, you will implement user-based CF with Mean-Center Normalisation.\n",
        "\n",
        "Provide implementations for `mean_rating(userId : str)` and `predict_rating_MC(userId : str, movieId : str)`.\n",
        "\n",
        "Hints: \n",
        "- See lecture 4 about user-based CF with Mean-center normalisation. \n",
        "- Check if the predicted rating for a given user makes sense (i.e. what did the user rate before)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBM4KVixYuPN"
      },
      "source": [
        "# index_of_non_zero_ratings = np.array(r_df_matrix.loc['u5']).nonzero()\n",
        "# r_df_matrix.loc['u5'][397]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q5Efb4zB5_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3332f3bb-7384-4f94-add6-c6e7c42cc0c4"
      },
      "source": [
        "def mean_rating(userId : str) -> float:\n",
        "  # add your solution here\n",
        "  \n",
        "  #only considering non-zero ratings\n",
        "\n",
        "  l = non_zero_ratings(userId)\n",
        "  val = np.mean(l)\n",
        "  mean_rating = val # mean-centering value\n",
        "  return mean_rating\n",
        "\n",
        "print(\"Mean rating of user u5:\", mean_rating('u5') )\n",
        "\n",
        "def predict_rating_MC(userId : str, movieId : str) -> float:\n",
        "  # add your solution here\n",
        "\n",
        "   top_userIds, top_cosines = get_most_similar_users(userId)\n",
        "   a = 0\n",
        "   l= []\n",
        "   #caculating mean centred ratings\n",
        "   for i in top_userIds:\n",
        "    l.append((r_df_matrix.loc[i][movieId] - mean_rating(i)) * top_cosines[a])\n",
        "    a = a+1\n",
        "   #calculating predictions\n",
        "   z = np.sum(l)/np.sum(top_cosines)\n",
        "   predicted = round((mean_rating(userId)+ z),2) # predicted rating value\n",
        "\n",
        "   # predicted rating value with mean-centering\n",
        "   return predicted\n",
        "\n",
        "print(\"Predicted rating:\", predict_rating_MC('u1', 'm1'))\n",
        "print(\"Actual rating:\", r_df_matrix.loc['u1']['m1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean rating of user u5: 3.6363636363636362\n",
            "Predicted rating: 3.13\n",
            "Actual rating: 4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VApK70ld1tQ_"
      },
      "source": [
        "Now answer the questions for Task 3 in the quiz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN_OpdQYHmTb"
      },
      "source": [
        "#Part B - Explicit Matrix Factorisation using Spotlight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17h6DqmGGh2f"
      },
      "source": [
        "In this part, we will investigate explicit matrix factorisation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0oobMGk5eqv"
      },
      "source": [
        "We're going to use the Spotlight library - see https://github.com/maciejkula/spotlight - and its documentation at https://maciejkula.github.io/spotlight/\n",
        "\n",
        "You can install this direct from Git, but using Craig's patched version as done below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDObURPI-Shz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b47adb-5c23-4bcc-8317-882329e87ecd"
      },
      "source": [
        "!pip install git+https://github.com/cmacdonald/spotlight.git@master#egg=spotlight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spotlight\n",
            "  Cloning https://github.com/cmacdonald/spotlight.git (to revision master) to /tmp/pip-install-1impeyfu/spotlight_d924a61c08c64fa88496e47f523ab6f4\n",
            "  Running command git clone -q https://github.com/cmacdonald/spotlight.git /tmp/pip-install-1impeyfu/spotlight_d924a61c08c64fa88496e47f523ab6f4\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spotlight) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->spotlight) (3.7.4.3)\n",
            "Building wheels for collected packages: spotlight\n",
            "  Building wheel for spotlight (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spotlight: filename=spotlight-0.1.6-py3-none-any.whl size=34106 sha256=a94ec8e9f5cf177807c85e3abe6311bf946c8eb12110f5f2c7f9fe2c7d835f34\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ydgxp0wn/wheels/1c/2a/31/d187173520bc800643df4e3d1f97dee21d2133ba41085704ed\n",
            "Successfully built spotlight\n",
            "Installing collected packages: spotlight\n",
            "Successfully installed spotlight-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqoiteq7IJzJ"
      },
      "source": [
        "Now we can get onto some real recommendation work. Spotlight has a handy [Interactions](https://maciejkula.github.io/spotlight/interactions.html) object, which encapsulates the basics of a recommendation dataset.\n",
        "\n",
        "In fact, there are handy loaders for a few standard datasets including MovieLens, but let's make our own, so that we can match back to the dataframe.\n",
        "\n",
        "Interactions need numbers as userids and itemids. Unfortunately, our MovieLens uses numbers, but these aren't consecutive (i.e. we have missing movieIds values). They are also strings (i.e. movieIds start with \"m\" and userIds start with \"u\").\n",
        "\n",
        "Hence, for both movies and users, we will use [defaultdict](https://docs.python.org/3/library/collections.html#collections.defaultdict) to convert the MovieLens strings down to consecutive integers for use in Spotlight, in the `uid_map` and `iid_map` objects. We'll keep the reverse mapping around too, in case we want to lookup the actual movieId given the uid recorded by Spotlight(etc).\n",
        "\n",
        "*NB*: This is a really important concept to understand. Put simply, WE -- as humans -- deal with external representations (userId, movieId, in this dataset prefixed with \"u\" and \"m\" respectively). On the other hand, Spotlight can only deal with integers starting from 0 for both items and users (we call these \"iids\" and \"uids\"). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtgpM_o1h0SF"
      },
      "source": [
        "# len(ratings_df['movieId'].unique())\n",
        "# len(ratings_df['movieId'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF89PzxNHrHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84aec19d-fcdb-40b6-c5d9-6b4c7afb7e1f"
      },
      "source": [
        "from collections import defaultdict\n",
        "from itertools import count\n",
        "\n",
        "#create userId -> uid mapping dictionary. the next assigned value is the current size.\n",
        "uid_map = defaultdict(count().__next__)\n",
        "#ditto for movieId -> iid\n",
        "iid_map = defaultdict(count().__next__)\n",
        "\n",
        "#uids is an array of integers corresponding to the userId for every row in ratings_df\n",
        "#uid_map does the assignment of new uid values, or reusing the uid value assigned for\n",
        "#each userId\n",
        "uids = np.array([uid_map[uid] for uid in ratings_df[\"userId\"].values ], dtype=np.int32)\n",
        "#similar for iids\n",
        "iids = np.array([iid_map[iid] for iid in ratings_df[\"movieId\"].values ], dtype=np.int32)\n",
        "\n",
        "#freeze uid_map and iid_map so no more mappings are created\n",
        "uid_map.default_factory = None\n",
        "iid_map.default_factory = None\n",
        "\n",
        "#reverse them, so we can go from iid (int) to itemId (str)\n",
        "uid_rev_map = {v: k for k, v in uid_map.items()}\n",
        "iid_rev_map = {v: k for k, v in iid_map.items()}\n",
        "num_items = len(iid_map)\n",
        "num_users = len(uid_map)\n",
        "\n",
        "print(\"%d users %d item\" % (num_users, num_items))\n",
        "\n",
        "ratings = ratings_df[\"rating\"].values.astype(np.float32)\n",
        "timestamps = ratings_df[\"timestamp\"].values.astype(np.int32)\n",
        "\n",
        "print(\"userId %s got uid %d\" % (\"u556\", uid_map[\"u556\"]))\n",
        "print(\"movieId %s got iid %d\" % (\"m54001\", iid_map[\"m54001\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "610 users 9724 item\n",
            "userId u556 got uid 555\n",
            "movieId m54001 got iid 2518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSY4aF3hjEQe"
      },
      "source": [
        "# len(ratings)\n",
        "# uid_map['u100']\n",
        "# iid_map['m2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrhni5wSX7QP"
      },
      "source": [
        "Furthemore, we will use user u556 as one of our illustrative users. You will remember from Exercise 1 that they rated a number of fantasy movies highly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDwZYy2xY3-D"
      },
      "source": [
        "## On towards MF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMejAIwPNVrU"
      },
      "source": [
        "Now let's build a Spotlight [Interactions](https://maciejkula.github.io/spotlight/interactions.html) object. This contains everything that Spotlight needs to train a model. We can split it up randomly into train and test subsets \n",
        "\n",
        "NB: we use a SEED (20) to make our results reproducible. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg2tNWwPIBfu"
      },
      "source": [
        "from spotlight.interactions import Interactions\n",
        "from spotlight.cross_validation import random_train_test_split\n",
        "\n",
        "dataset = Interactions(user_ids=uids,\n",
        "                                  item_ids=iids,\n",
        "                                  ratings=ratings,\n",
        "                                  timestamps=timestamps)\n",
        "\n",
        "#lets initialise the seed, so that its repeatable and reproducible \n",
        "train, test = random_train_test_split(dataset, random_state=np.random.RandomState(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1shoeRmWKXxS"
      },
      "source": [
        "Let's see how big the two datasets are. What is the train/test split percentage size?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcjOWJ-qIEge",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcf1c8b-0b4d-4f6a-abf8-0651bcc987f6"
      },
      "source": [
        "print(train)\n",
        "print(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Interactions dataset (610 users x 9724 items x 80668 interactions)>\n",
            "<Interactions dataset (610 users x 9724 items x 20168 interactions)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBnevuHnT57k"
      },
      "source": [
        "Here, you can see that following the collaborative filtering task model (see Lecture 6), all users, and all items, are present in both training and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTyhLswNulTX"
      },
      "source": [
        "Now, you can think of the Interaction objects are being the partitions of the rating matrix. But we don't store it as a single big matrix. Instead, we record three one-dimensional arrays:\n",
        " \n",
        "  * one for the ids of the users\n",
        "  * one for the ids of the items\n",
        "  * one for the actual rating values.\n",
        "\n",
        "Each of these arrays is the size of the number of ratings (80668 for the training set).\n",
        "\n",
        "In essence, Interactions is a sparse matrix - for each rating, we record its x and y position, as well as the rating itself.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74iQtBOoUZJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a106383-e8e5-4e33-c798-5d5243111c1d"
      },
      "source": [
        "print(train.item_ids.shape)\n",
        "print(train.user_ids.shape)\n",
        "print(train.ratings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80668,)\n",
            "(80668,)\n",
            "(80668,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V9Hx3dhUjI1"
      },
      "source": [
        "For instance, let's look at the first rating:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz46dNMkUrCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59e60e3-7c51-4af3-f832-9b84154785bc"
      },
      "source": [
        "print(\"uid %d gave iid %d a rating of %d\" % (train.user_ids[0], train.item_ids[0],train.ratings[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "uid 56 gave iid 1491 a rating of 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4R1mQgSUZ86"
      },
      "source": [
        "Let's take our favourite fantasy adventure fan from Exercise 1, userId u556. We can give a look at their training ratings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47QmgWtYvM4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a986252-b32c-4a1c-bc16-fa8c50b01e0b"
      },
      "source": [
        "# map userId to the internal uid value\n",
        "userId = \"u556\"\n",
        "uid = uid_map.get(userId)\n",
        "\n",
        "# see which ratings are for this user. Use this to filter the item and ratings arrays. \n",
        "# here we are filtering a numpy array based on an array of True/False values. Its just\n",
        "# like filtering a Pandas data frame.\n",
        "print(train.item_ids[train.user_ids == uid])\n",
        "print(train.ratings[train.user_ids == uid])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6082 6087  457 1925 7951 1132  764 5989  753 1342 1893 3076 3258 1182\n",
            " 1938 1894 4796  926  770 8659 2059  917 1077  912  779  322 1307 3087\n",
            " 2518  774]\n",
            "[4.  3.5 5.  5.  4.  4.  4.  4.  4.5 4.  4.  4.5 4.  4.  4.5 3.5 4.  4.\n",
            " 4.  4.  4.  3.5 5.  2.5 4.  5.  4.  4.  4.  4. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhnKAa-KKclT"
      },
      "source": [
        "We can now learn a model. Let's start with a matrix factorisation for explicit data.  We train the model using the `fit` method. This is just like the `fit` in Sklearn - we're fitting  a model to the specified training data.\n",
        "\n",
        "This might take upto a minute. \n",
        "\n",
        "**NB:**  Spotlight can support using GPUs which we could use to slightly speed up training time, but that will make our life more difficult later on, so let's ignore this for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UduCmnlbKt-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fee5f63-dc30-418f-8d52-00292ed92495"
      },
      "source": [
        "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
        "import time  \n",
        "\n",
        "emodel = ExplicitFactorizationModel(n_iter=10,\n",
        "                                    embedding_dim=32, #this is Spotlight default\n",
        "                                    use_cuda=False,\n",
        "                                    random_state=np.random.RandomState(SEED) # ensure results are repeatable\n",
        ")\n",
        "current = time.time()\n",
        "\n",
        "emodel.fit(train, verbose=True)\n",
        "\n",
        "end = time.time()\n",
        "diff = end - current\n",
        "print(\"Training took %d seconds \"% (diff))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: loss 4.308109082564523\n",
            "Epoch 1: loss 0.8099101057535485\n",
            "Epoch 2: loss 0.5096786639924291\n",
            "Epoch 3: loss 0.36366338065907927\n",
            "Epoch 4: loss 0.29197128183102306\n",
            "Epoch 5: loss 0.2569773988444594\n",
            "Epoch 6: loss 0.23643479901778547\n",
            "Epoch 7: loss 0.22271784107330478\n",
            "Epoch 8: loss 0.2139979843757575\n",
            "Epoch 9: loss 0.20728875342992287\n",
            "Training took 11 seconds \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTTK1BlbLL_t"
      },
      "source": [
        "How well did we do. Well, let's give a look at the recommentations, for our specific user, userId u556. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjyVPjoGLoy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16daeabf-5ecc-4ebf-ec61-b2f09d790465"
      },
      "source": [
        "userId = \"u556\"\n",
        "\n",
        "# convert the string to the internal integer\n",
        "uid = uid_map.get(userId)\n",
        "print(\"One test item_id for userId %s (uid %d) is \" % (userId, uid))\n",
        "\n",
        "# pick one rating that the user made\n",
        "testItemId = test.item_ids[test.user_ids == uid][0] \n",
        "print(\"Test movieId is %s iid %d \" % (iid_rev_map.get(testItemId), testItemId ) )\n",
        "\n",
        "\n",
        "#here 0 is a dummy item, which Spotlight needs for some reason...\n",
        "#we discard its prediction using [1]\n",
        "predicted = emodel.predict( np.array([uid]), item_ids=np.array([0, testItemId]) )[1]\n",
        "\n",
        "#what was the actual score of the user for that movie?\n",
        "#we can get the appropriate row from the ratings dataframe, then extract that value\n",
        "actual = ratings_df[(ratings_df.movieId==iid_rev_map.get(testItemId)) & (ratings_df.userId==userId)][\"rating\"].values[0]\n",
        "\n",
        "\n",
        "def getMovieTitle(iid):\n",
        "  return movies_df[movies_df['movieId'] == iid_rev_map.get(iid)][\"title\"].values[0]\n",
        "\n",
        "print(\"Predicted rating for '%s' was %f, actual rating %0.1f, error was %f\" % (getMovieTitle(testItemId), predicted, actual, abs(predicted-actual) )) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One test item_id for userId u556 (uid 555) is \n",
            "Test movieId is m74530 iid 8141 \n",
            "Predicted rating for 'Percy Jackson & the Olympians: The Lightning Thief (2010)' was 2.574090, actual rating 3.5, error was 0.925910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWdWW8QhacOw"
      },
      "source": [
        "So this is interesting - while we saw above that the users liked fantasy movies, we predicted a rating of $\\sim 2.5$, but the user gave this particular movie a 3.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgX01Wwlr_WA"
      },
      "source": [
        "We can also ask for **all** of the recommendations for a given user:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz28wrmIsDa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1cb2a1-a168-40ef-9f59-c9739498e757"
      },
      "source": [
        "allpreds = emodel.predict( np.array([uid]) )\n",
        "\n",
        "print(allpreds)\n",
        "print(allpreds.size)\n",
        "\n",
        "#we can recover the original rating for our test item \n",
        "print(allpreds[testItemId])\n",
        "\n",
        "# lets just check we got the correct prediction\n",
        "print(allpreds[testItemId] - actual < 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.9689238 4.3499794 4.5101576 ... 0.8742357 2.7873049 0.9850699]\n",
            "9724\n",
            "2.5740902\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d25P7AtBPgXS"
      },
      "source": [
        "## Latent Factors aka Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyL5EG65TuNo"
      },
      "source": [
        "Let's see how these recommendations are made. Remember from Lecture 8 that the prediction is made based on the dot product of the user's and item's latent factors (also know as \"embeddings\").\n",
        "\n",
        "We can access these embeddings directly from the emodel object. Each embedding has 32 dimensions, which is what we set when configuring Spotlight's Explicit Factorisation Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf2Em9KSa74G",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b891dede-7a5a-4def-c730-c14de4ce97c8"
      },
      "source": [
        "#the embedding of an item is a PyTorch tensor of size 32\n",
        "#a PyTorch tensor can be thought of having similar semantics as an numpy array.\n",
        "print(emodel._net.item_embeddings.weight[0].shape)\n",
        "emodel._net.item_embeddings.weight[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1223, -0.3951, -0.3488,  0.0474,  0.7867, -0.0242,  0.2448,  0.7672,\n",
              "        -0.1924, -0.0686, -0.1228,  0.6061, -0.1798, -0.3621,  0.7326,  0.2025,\n",
              "        -0.1660, -0.3077, -0.3590, -0.3852,  0.2369, -0.6257,  0.7370,  0.8468,\n",
              "         0.0755, -0.4360, -0.1154, -0.2451, -0.0357, -0.0060,  0.1001,  0.2164],\n",
              "       grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcKlJIBoVNYr"
      },
      "source": [
        "We can check how Spotlight makes its prediction. The key line is https://github.com/maciejkula/spotlight/blob/master/spotlight/factorization/representations.py#L89\n",
        "\n",
        "This takes the (dot-)product of the user's \"embedding\" (latent factor) and the item's embedding. On top of these are added \"user_biases\" and \"item_biases\". What do you think these last two components are for?\n",
        "\n",
        "Let's reproduce this for our favourite user..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g14v62m4YRyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232a6f9c-48ab-4d41-8f68-9f83120d41c0"
      },
      "source": [
        "# uid=555 for u556\n",
        "# testItemId is our item of interest\n",
        "\n",
        "dotprod = (emodel._net.user_embeddings.weight[uid] * emodel._net.item_embeddings.weight[testItemId]).sum(0)\n",
        "user_bias = emodel._net.user_biases(torch.tensor([uid]))\n",
        "item_bias = emodel._net.item_biases(torch.tensor([testItemId], dtype=torch.long))\n",
        "\n",
        "print(getMovieTitle(testItemId))\n",
        "\n",
        "dotprod + user_bias + item_bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percy Jackson & the Olympians: The Lightning Thief (2010)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.5741]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VE2tpcJb8e7"
      },
      "source": [
        "## Task 4. Examining Latent Factors\n",
        "\n",
        "Let's give a look at item-item similarities. Write a function `mostsimilar(targetMovieId, model)` that identifies the most similar movieId to the specified target, based on the Cosine similarity of their item embedding vectors. \n",
        "\n",
        "What's the closest movie to \"Harry Potter and the Deathly Hallows: Part 1 (2010)\" , which is movieId m81834 in the MovieLens dataset?\n",
        "\n",
        "Hint: \n",
        " - Since we're working with PyTorch tenors, you should use [`nn.functional.cosine_similarity(x, y, dim=0)`](https://pytorch.org/docs/stable/nn.functional.html#cosine-similarity) to calculate the cosine similarity between two vectors x & y, as demonstrated below between two orthogonal vectors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7fDGUx6fBR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12865856-0ed5-458e-9397-805e712fa4b5"
      },
      "source": [
        "import torch.nn as nn\n",
        "nn.functional.cosine_similarity(\n",
        "     torch.tensor([1.0,0]),\n",
        "     torch.tensor([0,1.0],), dim=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_st28xi8tJ-D"
      },
      "source": [
        "\n",
        "# cosine_values = []\n",
        "# for i in range(0, emodel._num_items):\n",
        "#     # a = r_df_matrix.index[i]\n",
        "#     # similar_uids.append(a)\n",
        "#     b = nn.functional.cosine_similarity(emodel._net.item_embeddings.weight[iid_map[\"m81834\"]],emodel._net.item_embeddings.weight[i],dim =0)\n",
        "#     cosine_values.append(b)\n",
        "# # print((cosine_values[1952]))\n",
        "# rankdata(cosine_values).argsort()[::-1][1]\n",
        "# cosine_values[917]\n",
        "\n",
        "# # iid_rev_map.get(917)\n",
        "# # getMovieTitle(917)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rg_DuBnoMEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b843a0-914f-43db-a463-c0dbf1530e92"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def mostsimilar(targetIId : int, model):\n",
        "  highest=0\n",
        "  highestCos=0\n",
        "  \n",
        "  #you may assume that model._num_items provides thetotal number of items\n",
        "  \n",
        "  \n",
        "  ##SOLUTION FROM HERE\n",
        "\n",
        "  #####################\n",
        "\n",
        "  cosine_values = []\n",
        "  for i in range(0, model._num_items):\n",
        "    item_embeddings_targetIid = emodel._net.item_embeddings.weight[targetIId]\n",
        "    item_embeddings_i = emodel._net.item_embeddings.weight[i]\n",
        "    cos_val = nn.functional.cosine_similarity(item_embeddings_targetIid ,item_embeddings_i,dim =0)\n",
        "    cosine_values.append(cos_val)\n",
        "\n",
        "  highest = rankdata(cosine_values).argsort()[::-1][1]\n",
        "  highestCos = cosine_values[highest]\n",
        "  \n",
        "\n",
        "\n",
        "  print(train.num_items)\n",
        "  print(\"targetMovieId = %s '%s' (iid %d)\" % (iid_rev_map.get(targetIId), getMovieTitle(targetIId), targetIId))\n",
        "  print(\"mostSimilar = %s (iid %d) with cosine of %f \" % ( iid_rev_map.get(highest), highest, highestCos))\n",
        "  print('most similar movie title %s' %(getMovieTitle(highest)))\n",
        "  \n",
        "mostsimilar(iid_map[\"m81834\"], emodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9724\n",
            "targetMovieId = m81834 'Harry Potter and the Deathly Hallows: Part 1 (2010)' (iid 1933)\n",
            "mostSimilar = m69844 (iid 917) with cosine of 0.793590 \n",
            "most similar movie title Harry Potter and the Half-Blood Prince (2009)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Br4nChVqUAj"
      },
      "source": [
        "Hopefully, you can see a correspondence between the nearest movie to `\"m81834\"`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgUvFR0AK8XI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aedefde1-905d-4dfa-b88c-d590e2e7e19a"
      },
      "source": [
        "mostsimilar(iid_map[\"m88125\"], emodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9724\n",
            "targetMovieId = m88125 'Harry Potter and the Deathly Hallows: Part 2 (2011)' (iid 1938)\n",
            "mostSimilar = m69844 (iid 917) with cosine of 0.765978 \n",
            "most similar movie title Harry Potter and the Half-Blood Prince (2009)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENhT5FXX3qH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c93461ae-8181-499f-c202-61ea1c272246"
      },
      "source": [
        "mostsimilar(iid_map[\"m44\"], emodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9724\n",
            "targetMovieId = m44 'Mortal Kombat (1995)' (iid 971)\n",
            "mostSimilar = m107338 (iid 2836) with cosine of 0.641704 \n",
            "most similar movie title Dampfnudelblues (2013)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxHfMZgbcdRu"
      },
      "source": [
        "## Evaluating performance\n",
        "\n",
        "Finally, let's see how good we are at our rating predictions. Handily, Spotlight implements a few common evaluation measures for us to inspect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB8UJykycm3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f901b0e4-2a6d-40e0-bf79-2d953f61e1d5"
      },
      "source": [
        "from spotlight.evaluation import rmse_score\n",
        "\n",
        "train_rmse = rmse_score(emodel, train)\n",
        "test_rmse = rmse_score(emodel, test)\n",
        "\n",
        "print('Train RMSE {:.3f}, test RMSE {:.3f}'.format(train_rmse, test_rmse))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train RMSE 0.421, test RMSE 1.078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcRrTWx9lkoo"
      },
      "source": [
        "## Task 5. Tuning\n",
        "\n",
        "It's appropriate to tune the latent factors. Normally we would use a held-out *validation* for setting the parameters, but as an exercise it is useful to examine performance on the training and test data.\n",
        "\n",
        "The task here is to train and evaluate new instances of ExplicitFactorizationModels using different numbers of latent factors, while leaving the other parameters unchanged (i.e. `n_iter=10, use_cuda=False, random_state=np.random.RandomState(SEED)`. \n",
        "\n",
        "You should also record the training times for different numbers of latent factors.\n",
        "\n",
        "You should vary the factors in `[8,16,32,64]`. Evaluate and record the RMSE values of the resulting models on both the training and test sets. Use matplotlib to create a graph showing how training and test RMSE change as the number of latent factors is varied. Use [plt.savefig()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html) to save a PNG of your graph.\n",
        "\n",
        "You can now answer the questions about Task 5 in the quiz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKXhGfhv256T"
      },
      "source": [
        "# # for k in [8,16,32,64]:\n",
        "# #   print(\"------ For Latent Factor ------ %d\" %(k))\n",
        "# a = ExplicitFactorizationModel(n_iter=10,\n",
        "#                                     embedding_dim=8, #varying the values \n",
        "#                                     use_cuda=False,\n",
        "#                                     random_state=np.random.RandomState(SEED))\n",
        "# current = time.time()\n",
        "\n",
        "# a.fit(train, verbose=True)\n",
        "\n",
        "# end = time.time()\n",
        "# diff = end - current\n",
        "# print(\"Training took %d seconds \"% (diff))\n",
        "\n",
        "# print(a._net.item_embeddings.weight[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG8dFwv06z_G"
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "\n",
        "# # gca stands for 'get current axis'\n",
        "# ax = plt.gca()\n",
        "# data = {'Latent Factors': [8,16,32,64],\n",
        "#         'rmse_train': [9.8,12,8,7.2],\n",
        "#         'rmse_test': [6.9,7,6.5,6.2]\n",
        "#        }\n",
        "  \n",
        "# df = pd.DataFrame(data,columns=['Latent Factors','rmse_train','rmse_test'])\n",
        "\n",
        "# df.plot(kind='line',x='Latent Factors',y='rmse_train',ax=ax)\n",
        "# df.plot(kind='line',x='Latent Factors',y='rmse_test', color='red', ax=ax)\n",
        "# plt.ylabel('RMSE')\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42zBfjCEL6pI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "294cef5b-b408-4773-b909-641f812cc013"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "#solution here\n",
        "\n",
        "rmse_train = []\n",
        "rmse_test = []\n",
        "\n",
        "for k in [8,16,32,64]:\n",
        "  print(\"------ For Latent Factor ------ %d \\n \" %(k))\n",
        "  emodel = ExplicitFactorizationModel(n_iter=10,\n",
        "                                    embedding_dim=k, #varying the values \n",
        "                                    use_cuda=False,\n",
        "                                    random_state=np.random.RandomState(SEED))\n",
        "  current = time.time()\n",
        "  emodel.fit(train, verbose=True)\n",
        "  end = time.time()\n",
        "  diff = end - current\n",
        "  print(\"\\n Training for %d latent factor took %d seconds \"% (k,diff))\n",
        "  # print(emodel._net.item_embeddings.weight[0].shape)\n",
        "\n",
        "  # Evaluate RMSE values of the resulting models on both the training and test sets.\n",
        "  train_rmse = rmse_score(emodel, train)\n",
        "  rmse_train.append(train_rmse)\n",
        "  test_rmse = rmse_score(emodel, test)\n",
        "  rmse_test.append(test_rmse)\n",
        "\n",
        "  print('\\n Train RMSE {:.3f}, test RMSE {:.3f}'.format(train_rmse, test_rmse))\n",
        "  print('--------------------------------------------------------------------\\n')\n",
        "\n",
        "  # matplotlib\n",
        "ax = plt.gca()\n",
        "data = {'Latent Factors': [8,16,32,64],\n",
        "        'RMSE_train': rmse_train,\n",
        "        'RMSE_test': rmse_test\n",
        "       }\n",
        "  \n",
        "df = pd.DataFrame(data,columns=['Latent Factors','RMSE_train','RMSE_test'])\n",
        "\n",
        "df.plot(kind='line',x='Latent Factors',y='RMSE_train',ax=ax)\n",
        "df.plot(kind='line',x='Latent Factors',y='RMSE_test', color='red', ax=ax)\n",
        "plt.ylabel('RMSE')\n",
        "plt.savefig('task5.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ For Latent Factor ------ 8 \n",
            " \n",
            "Epoch 0: loss 5.744367670032043\n",
            "Epoch 1: loss 0.947946014472201\n",
            "Epoch 2: loss 0.6766490363810636\n",
            "Epoch 3: loss 0.5712967022687574\n",
            "Epoch 4: loss 0.5091710749872124\n",
            "Epoch 5: loss 0.4707542299469815\n",
            "Epoch 6: loss 0.4421984958875028\n",
            "Epoch 7: loss 0.4213783264726023\n",
            "Epoch 8: loss 0.40568301392884193\n",
            "Epoch 9: loss 0.3946505979269366\n",
            "\n",
            " Training for 8 latent factor took 7 seconds \n",
            "\n",
            " Train RMSE 0.577, test RMSE 1.011\n",
            "--------------------------------------------------------------------\n",
            "\n",
            "------ For Latent Factor ------ 16 \n",
            " \n",
            "Epoch 0: loss 4.747190544311004\n",
            "Epoch 1: loss 0.8711058652099175\n",
            "Epoch 2: loss 0.6259694243722325\n",
            "Epoch 3: loss 0.4961913288394107\n",
            "Epoch 4: loss 0.41484170680559135\n",
            "Epoch 5: loss 0.36290632853213745\n",
            "Epoch 6: loss 0.33110926969896387\n",
            "Epoch 7: loss 0.30869432774525657\n",
            "Epoch 8: loss 0.29521983975096594\n",
            "Epoch 9: loss 0.28318326660915266\n",
            "\n",
            " Training for 16 latent factor took 8 seconds \n",
            "\n",
            " Train RMSE 0.483, test RMSE 1.048\n",
            "--------------------------------------------------------------------\n",
            "\n",
            "------ For Latent Factor ------ 32 \n",
            " \n",
            "Epoch 0: loss 4.308109082564523\n",
            "Epoch 1: loss 0.8099101057535485\n",
            "Epoch 2: loss 0.5096786639924291\n",
            "Epoch 3: loss 0.36366338065907927\n",
            "Epoch 4: loss 0.29197128183102306\n",
            "Epoch 5: loss 0.2569773988444594\n",
            "Epoch 6: loss 0.23643479901778547\n",
            "Epoch 7: loss 0.22271784107330478\n",
            "Epoch 8: loss 0.2139979843757575\n",
            "Epoch 9: loss 0.20728875342992287\n",
            "\n",
            " Training for 32 latent factor took 11 seconds \n",
            "\n",
            " Train RMSE 0.421, test RMSE 1.078\n",
            "--------------------------------------------------------------------\n",
            "\n",
            "------ For Latent Factor ------ 64 \n",
            " \n",
            "Epoch 0: loss 3.9413014178789116\n",
            "Epoch 1: loss 0.7578930015428157\n",
            "Epoch 2: loss 0.4151066039936452\n",
            "Epoch 3: loss 0.2889488877940781\n",
            "Epoch 4: loss 0.25092152270335183\n",
            "Epoch 5: loss 0.24193845896781246\n",
            "Epoch 6: loss 0.2406937820907635\n",
            "Epoch 7: loss 0.2387842084222202\n",
            "Epoch 8: loss 0.23337349620989606\n",
            "Epoch 9: loss 0.22632360265036172\n",
            "\n",
            " Training for 64 latent factor took 17 seconds \n",
            "\n",
            " Train RMSE 0.468, test RMSE 1.038\n",
            "--------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3wV9Z3/8dcnN0ICJCGJCAQKWlQQMWjq/YJaFbyg7boWtxdr3bJtvUvt6q72Yre79kfrrbVa13XtZSva2laqbcW7Vqs1aFCugghNQCQGAoRbQvj8/phJchJOruTk5GTez8fjPDJnZs6c74Twfc98vzPfMXdHRESiKy3ZBRARkeRSEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMRlJGrDZvYgcB6w0d0nx1l+GPC/wFHAv7v7D7qy3aKiIh83blxvFlVEZMBbuHDhR+5eHG9ZwoIAeAj4MfDzdpZvAq4GLuzORseNG0d5efn+lUxEJGLMbG17yxLWNOTuLxFU9u0t3+jubwANiSqDiIh0Tn0EIiIRlxJBYGazzazczMqrq6uTXRwRkQElJYLA3e939zJ3LysujtvXISIiPZQSQSAiIomTyMtHHwamAUVmVgV8C8gEcPf7zOxAoBwYBuw1s2uBSe6+NVFlEhGRfSUsCNz9kk6WbwBKEvX9IiLSNYm8j0Ckf9i2Ddatg6qq4Of69ZCWBsOHx3/l5IBZskst0mcUBJK69u6FjRuDyr3p1VTZx05v29a97WZltR8SHb2GDVOASEpSEEj/tGtXcOTeXuXedGS/Z0/rz6Wnw8iRMHo0TJoEZ50VTDe9Skpg1Khg3U2buvZauxbeeiuY3r69/TKnp0NBQfcDJD8/+KxIkigIpG+5Q21t6wo9XmVfU7PvZ3NzWyrzU09tXbk3TY8Y0fVKNScn+Gx37N4Nmzd3LUA+/BCWLQumt2zpeLv5+d0PkIKC4OxFZD8pCKT37NkDGzZ03Eyzbh3s3LnvZw84IKjIx4yB44/f9yh+9Oj+0fQyaBAceGDw6o49e4IA7OpZyPvvBz83bw6awNozZEjPmrEGD96/34MMKAoC6Zrt2zuu3NetC0KgbaWVlRU0xZSUwNFHw8yZ+x7FjxwZVLADWUYGFBUFr+7Yuxe2bu16gCxZ0jLd0MEwXtnZPQuQIUOSH8bS6xQEUbd3L3z0UecdrvGaNvLzWyrzyZNbV+5N00VFqjj2R1pa8HvOz4eDDur659yD8G4bFO01a61eDeXlwfSOHe1vNyOjZwGSlxfsi/RLCoKBrL6+ax2u9fWtP5eWFjR9lJTAoYfC6afvexQ/enTQZi/9k1lw9D5kCIwd273P7trV9X6Q9eth8eJgemsH94Kada0jve06BQWQmbl/vwvplIIgFbkH/+k663CNN0BfTk5LRX7iiftW7iUlQYdrhv40Iis7O2iuGzmye59raOheP8iqVS1nKe7tb3fo0J6dhWRn79/vIUL0v70/cg+uNnn33faP5ONdxlhU1FKZf+IT8Y/i8/PVVCOJkZkJxcXBqzv27g2aHrsaIO+80zLd9vLhWIMH9yxAcnMj939EQdAfuMPKlfD88y2vjRtblmdmBh2uo0fDkUfCuefGvzZ+oHe4ysCUlhY0ARUUwMEHd/1z7lBX1/UAWbky+FlTE1wG3J7MzJ7fUJii/SAKgmR5//3WFf+6dcH80aODm6BOOw1KS4P3xcUp+wcmkjBmQbPR0KHwsY9177M7d3Y9QCorYdGiYLqurv1tNgVaT24oTHJTrIKgr1RVta7416wJ5h9wQFDpn3Za0Cn78Y9H7rRUpM8NHtxyRt0d9fVd70ivroYVK4Lp2tqOt5uX17XQmDgRJkzo+X63Q0GQKB9+2LriX7kymD98OEybBnPmBBX/xImq+EVSRVZWcDHFiBHd+1xjY/c60teubZmOvTfnxhvhv/6rd/cJBUHvqamBF15oqfiXLg3mDxsWDIfw1a8GR/1TpqiZRyRq0tOhsDB4dcfevcGgiU2h0N3Pd5GCoKe2bIGXXoLnngsq/rffDjqvcnPh5JPh0kuDin/q1KS3/4lIikpLC5qN8vJg/PiEfY1qqK6qq4O//KWl4n/zzSCts7PhhBPgu98NKv5PfEI3wIhISlEQtGfnTnj11aDSf+45eOON4JrlzEw47ji45Zag4j/2WN24IiIpTUHQZPdueP31lor/tdeCKwTS04Oj/G98I6j4TzghuDtXRGSAiG4QNDQEg2w1VfyvvhqcBZjBUUfB1VcHV/WcdFJwnbKIyAAVnSBobAyeMtV0Vc/LL7fcHDJlCsyeHRzxn3JKcFOIiEhEJCwIzOxB4Dxgo7tPjrPcgLuAc4AdwBfd/c1ElYdf/AIuuyyYnjgRvvCFoOI/9dTuj40iIjKAJPKM4CHgx8DP21k+A5gQvo4F7g1/JsbZZ8OvfhXczNXdURVFRAawhAWBu79kZuM6WOUC4Ofu7sBrZpZvZiPd/YOEFGjkSLjkkoRsWkQklSXzFtfRQGXM+6pwnoiI9KGUGOvAzGabWbmZlVfHe9iKiIj0WDKDYB0wJuZ9SThvH+5+v7uXuXtZsTp2RUR6VTKDYD7wBQscB2xJWP+AiIi0K5GXjz4MTAOKzKwK+BaQCeDu9wF/JLh0dBXB5aOXJaosIiLSvkReNdThJTrh1UJXJOr7RUSka1Kis1hERBJHQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOISGgRmNt3MVpjZKjO7Mc7yj5nZs2b2tpm9YGYliSyPiIjsK2FBYGbpwD3ADGAScImZTWqz2g+An7v7FOBW4L8SVR4REYkvkWcExwCr3H21u9cD84AL2qwzCXgunH4+znIREUmwRAbBaKAy5n1VOC/WIuDT4fSngKFmVpjAMomISBvJ7iz+OnCqmb0FnAqsAxrbrmRms82s3MzKq6ur+7qMIiIDWiKDYB0wJuZ9STivmbuvd/dPu/tU4N/DebVtN+Tu97t7mbuXFRcXJ7DIIiLRk8ggeAOYYGbjzSwLmAXMj13BzIrMrKkMNwEPJrA8IiISR8KCwN33AFcCTwHLgEfdfYmZ3WpmM8PVpgErzOxdYATwvUSVR0RE4jN3T3YZuqWsrMzLy8uTXQwRkZRiZgvdvSzesmR3FouISJIpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRFxCg8DMppvZCjNbZWY3xlk+1syeN7O3zOxtMzsnkeUREZF9JSwIzCwduAeYAUwCLjGzSW1Wuxl41N2nArOAnySqPCIiEl9GArd9DLDK3VcDmNk84AJgacw6DgwLp/OA9Qksj4gkSUNDA1VVVezatSvZRRnwsrOzKSkpITMzs8ufSWQQjAYqY95XAce2WefbwAIzuwrIBT6ZwPKISJJUVVUxdOhQxo0bh5kluzgDlrtTU1NDVVUV48eP7/Lnkt1ZfAnwkLuXAOcAvzCzfcpkZrPNrNzMyqurq/u8kCKyf3bt2kVhYaFCIMHMjMLCwm6feSUyCNYBY2Lel4TzYl0OPArg7n8FsoGithty9/vdvczdy4qLixNUXBFJJIVA3+jJ7zmRQfAGMMHMxptZFkFn8Pw26/wdOAPAzCYSBIEO+UVE+lDCgsDd9wBXAk8BywiuDlpiZrea2cxwtTnAl81sEfAw8EV390SVSUSiKz09ndLSUiZPnsz5559PbW0tAGvWrMHMuPnmm5vX/eijj8jMzOTKK68EYMWKFUybNo3S0lImTpzI7NmzAXjhhRfIy8ujtLS0+fXMM8/E/f7a2lp+8pOeXRh5zjnnNJc3EToMAjM7PWZ6fJtln+5s4+7+R3c/xN0PdvfvhfO+6e7zw+ml7n6iux/p7qXuvqBnuyEi0rHBgwdTUVHB4sWLGT58OPfcc0/zsvHjx/Pkk082v//1r3/N4Ycf3vz+6quv5rrrrqOiooJly5Zx1VVXNS87+eSTqaioaH598pPxr3npKAj27NnTYdn/+Mc/kp+f36X97InOrhr6AXBUOP1YzDQE9wD8NhGFEpGB6zt/WMLS9Vt7dZuTRg3jW+cf3vmKoeOPP5633367+X1OTg4TJ06kvLycsrIyHnnkES6++GLWrw+uaP/ggw8oKSlpXv+II47odhlvvPFG3nvvPUpLSznzzDM599xzueWWWygoKGD58uW8++67XHjhhVRWVrJr1y6uueaa5jOPcePGUV5eTl1dHTNmzOCkk07i1VdfZfTo0Tz++OMMHjy42+WJ1VnTkLUzHe+9iEi/19jYyLPPPsvMmTNbzZ81axbz5s2jsrKS9PR0Ro0a1bzsuuuu4/TTT2fGjBnccccdrZppXn755VZNQ++9917c773ttts4+OCDqaioYO7cuQC8+eab3HXXXbz77rsAPPjggyxcuJDy8nLuvvtuampq9tnOypUrueKKK1iyZAn5+fk89thj+/076eyMwNuZjvdeRKRT3Tly7007d+6ktLSUdevWMXHiRM4888xWy6dPn84tt9zCiBEj+MxnPtNq2WWXXcbZZ5/Nn//8Zx5//HF++tOfsmjRIiBoGnriiSd6VKZjjjmm1fX+d999N7/73e8AqKysZOXKlRQWFrb6zPjx4yktLQXg6KOPZs2aNT367lidnREcZGbzzewPMdNN77t+t4KISJI19RGsXbsWd2/VRwCQlZXF0UcfzQ9/+EMuuuiifT4/atQovvSlL/H444+TkZHB4sWL97tMubm5zdMvvPACzzzzDH/9619ZtGgRU6dOjXs/wKBBg5qn09PTO+1f6IrOzgguiJn+QZtlbd+LiPR7OTk53H333Vx44YV87Wtfa7Vszpw5nHrqqQwfPrzV/D//+c+cccYZZGZmsmHDBmpqahg9ejTLly/v8vcOHTqUbdu2tbt8y5YtFBQUkJOTw/Lly3nttde6t2P7ocMgcPcXY9+bWSYwGVjn7hsTWTARkUSZOnUqU6ZM4eGHH+bkk09unn/44Ye3ulqoyYIFC7jmmmvIzs4GYO7cuRx44IEsX768uY+gyc033xz3jKKwsJATTzyRyZMnM2PGDM4999xWy6dPn859993HxIkTOfTQQznuuON6a3c7ZR1dtm9m9wE/Cq//zwP+CjQCw4Gvu/vDfVPMFmVlZV5eXt7XXysi+2HZsmVMnDgx2cWIjHi/bzNb6O5l8dbvrI/gZHdfEk5fBrzr7kcARwPf2N/CiohI8nXWR1AfM30m8GsAd9+gcUNERPZVU1PDGWecsc/8Z599dp8rgPqLzoKg1szOIxgs7kSCQeIwswxg/+5gEBEZgAoLC6moqEh2MbqlsyD4F+Bu4EDgWnffEM4/A3iy3U+JiEjK6OyqoXeB6XHmP0UwmJyIiKS4DoPAzO7uaLm7X927xRERkb7WWdPQV4DFBA+PWY/GFxIRGXA6u3x0JHA/cDbweSATeNzdf+buP0t04UREeksqP48A4M4772THjh09/nxHOgwCd69x9/vc/TSC+wjygaVm9vmElEZEJEH68/MIuiKRQdBZ0xAAZnYUwYPmzwT+BCxMSGlEZOC79lro7csrS0vhzju7vHp/eB7B3LlzmTt3Lo8++ii7d+/mU5/6FN/5znfYvn07F198MVVVVTQ2NnLLLbfw4Ycfsn79ek477TSKiop4/vnnu/39Hemss/hW4FyCR03OA24KH0EpIpKSmp5HcPnll7ea3/Q8ghEjRjQ/j6ApCJqeR3DCCSdw1llncdlllzU/MaztWEOPPfYYBx988D7fe9ttt7F48eLmewwWLFjAypUr+dvf/oa7M3PmTF566SWqq6sZNWpU8xnKli1byMvL4/bbb+f555+nqKio138nnZ0R3Ay8DxwZvv4zvKPYAHf3Kb1eIhEZ2Lpx5N6b+tvzCBYsWMCCBQuYOnUqAHV1daxcuZKTTz6ZOXPm8K//+q+cd955rQbFS5TOOovHA6cD54Wv88NX07SISErob88jcHduuumm5r6FVatWcfnll3PIIYfw5ptvcsQRR3DzzTdz66237tf3dEVnncVr472ASuCkhJdORKSXNT2P4Ic//OE+D3WZM2cO3//+9+M+j6ChoQGg1fMIuqPt8wjOPvtsHnzwQerq6gBYt24dGzduZP369eTk5PC5z32OG264gTfffDPu53tTZ30Ew4ArgNHAfOBp4EpgDrAI+L+ElEpEJIH6w/MI5s6dy7Jlyzj++OMBGDJkCL/85S9ZtWoVN9xwA2lpaWRmZnLvvfcCMHv2bKZPn86oUaN6vbO4s+cRPA5sJngOwRnAAQT9A9e4e6fd/mY2HbgLSAcecPfb2iy/AzgtfJsDHODu+R1tU88jEEk9eh5B3+ru8wg66yw+KHz+AGb2APABMNbd932QZhtmlg7cQ3DJaRXwhpnNd/elTeu4+3Ux618FTO1suyIi0rs6C4KGpgl3bzSzqq6EQOgYYJW7rwYws3kEz0Be2s76lwDf6uK2RUT6pYH4PIIjzWxrOG3A4PB90+Wjwzr47GiCTuUmVcCx8VY0s48RXKH0XDvLZwOzAcaOHdtJkUWkP3J3ovBAq2Q/j6Cj5v72dHbVULq7DwtfQ909I2a6oxDorlnAb9y9sZ1y3O/uZe5eVlxc3ItfKyJ9ITs7m5qamh5VUtJ17k5NTU1zp3ZXdWmIiR5aB4yJeV8SzotnFsHVSSIyAJWUlFBVVUV1dXWyizLgZWdntxoOoysSGQRvABPMbDxBAMwC/qntSmZ2GFBAcGWSiAxAmZmZjB8/PtnFkHZ0dmdxj4VjEl1J8CSzZcCj7r7EzG41s5kxq84C5rnOGUVEkiKRZwS4+x+BP7aZ980277+dyDKIiEjHEnZGICIiqUFBICIScQoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4hIaBGY23cxWmNkqM7uxnXUuNrOlZrbEzH6VyPKIiMi+MhK1YTNLB+4BzgSqgDfMbL67L41ZZwJwE3Ciu282swMSVR4REYkvkWcExwCr3H21u9cD84AL2qzzZeAed98M4O4bE1geERGJI5FBMBqojHlfFc6LdQhwiJm9Ymavmdn0eBsys9lmVm5m5dXV1QkqrohINCW7szgDmABMAy4B/tvM8tuu5O73u3uZu5cVFxf3cRFFRAa2RAbBOmBMzPuScF6sKmC+uze4+/vAuwTBICIifSSRQfAGMMHMxptZFjALmN9mnd8TnA1gZkUETUWrE1gmERFpI2FB4O57gCuBp4BlwKPuvsTMbjWzmeFqTwE1ZrYUeB64wd1rElUmERHZl7l7ssvQLWVlZV5eXt6jz7o7ZtbLJRIR6f/MbKG7l8VbluzO4j6zYsM2LvzJqyxetyXZRRER6VciEwQ123ezvnYnF9zzCrf9aTm7GhqTXSQRkX4hMkFwwsFFPHPdqVx0VAn3vfgeM+56mddXqztCRCQyQQCQl5PJ9y+awi8vP5aGxr185v7XuOX3i9m2qyHZRRMRSZpIBUGTkyYUseC6U/jSieP55etrOfuOl3h+uUa3EJFoimQQAORkZfDN8yfx2FdPIHdQBpc99AbXPVLBpu31yS6aiEifimwQNDlqbAFPXH0SV58xgT8sWs+Zt7/IHxatJ9UuqxUR6anIBwHAoIx0rj/zEP5w1UmMLhjMVQ+/xZd/vpAPt+5KdtFERBJOQRBj4shh/ParJ/Bv5xzGyyur+eTtLzLvb3/X2YGIDGgKgjYy0tOYfcrBPHXtKUwaOYwbf/sOn33gddbWbE920UREEkJB0I5xRbk8/OXj+M9PHcE7VVs4+86XeODl1TTu1dmBiAwsCoIOpKUZ/3TsWBZcfwonHlzEfzy5jE/f+yorNmxLdtFERHqNgqALRuYN5oFLy7j7kqlUbtrBeT96mTufeZf6PXuTXTQRkf2mIOgiM2PmkaN45vpTOeeIkdz5zErO/9FfqKisTXbRRET2i4Kgm4bnZnHXrKn8z6VlbNnZwKd/8gr/8cRSdtZrEDsRSU0Kgh46Y+IInr7+FC45ZiwP/OV9zr7zJV5976NkF0tEpNsUBPthaHYm3/vUEcybfRxpBv/0369z02/fZstODWInIqlDQdALjjuokD9dcwr/cspBPPJGJWfd8SJPL/0w2cUSEekSBUEvGZyVzk3nTOT3V5xIQU4WX/55OVf+6k0+qtud7KKJiHRIQdDLppTkM//Kk5hz5iEsWPIhZ97+Ir9/a52GqRCRfktBkABZGWlcdcYEnrz6JMYV5XLtIxV86aE3WF+7M9lFExHZR0KDwMymm9kKM1tlZjfGWf5FM6s2s4rw9c+JLE9fmzBiKL/5ygl86/xJvLZ6E2fd8RK/eG0tezVMhYj0IwkLAjNLB+4BZgCTgEvMbFKcVR9x99Lw9UCiypMs6WnGZSeOZ8F1p1A6Jp9bfr+YWfe/xurqumQXTUQESOwZwTHAKndf7e71wDzgggR+X782ZngOv7j8GP7fRVNYvmErM+56mftefI89jRqmQkSSK5FBMBqojHlfFc5r6x/M7G0z+42ZjYm3ITObbWblZlZeXV2diLL2CTPj4rIxPHP9qUw7tJjb/rScC3/yCkvXb0120UQkwpLdWfwHYJy7TwGeBn4WbyV3v9/dy9y9rLi4uE8LmAgHDMvmp58v497PHsWGLbuZ+eO/8IOnVrCrQcNUiEjfS2QQrANij/BLwnnN3L3G3ZsutH8AODqB5el3ZhwxkmeuP4ULSkfz4+dXce7dL7Nw7aZkF0tEIiaRQfAGMMHMxptZFjALmB+7gpmNjHk7E1iWwPL0S/k5Wfzw4iP52ZeOYVfDXi667698e/4Stu/ek+yiiUhEZCRqw+6+x8yuBJ4C0oEH3X2Jmd0KlLv7fOBqM5sJ7AE2AV9MVHn6u1MPKWbBdacw96kV/Oyva3h66Yd85dSDmDq2gMMOHEpGerJb8URkoLJUu+O1rKzMy8vLk12MhCpfs4mbfvsOKzcGl5hmZ6ZxxOg8SsfkUzqmgNKx+YzKy8bMklxSEUkVZrbQ3cviLlMQ9E/uTuWmnbxVuZmKyloqKmtZsn5r81PRiocOCoMhn6lj8pkyJp8hgxJ2giciKa6jIFDN0U+ZGWMLcxhbmMMFpcFVt/V79rLsg63NwVBRWds8yqkZTDhgSMtZw5h8DhkxRE1KItIpnRGkuNod9a2CYVFlLZt3BM9DGJyZzhEleUwNzxxKx+YzMm9wkkssIj3l7j1uEtYZwQCWn5PFtEMPYNqhBwDBH8ramh3NwfBWZS3/+8oa6sM7mEcMG9TqrGFKSR65alISSYpdDY3UbK9nU109Ndt3s3lHPTV19WzaHrxqttezOWb60hPGcf2Zh/R6OVQDDDBmxriiXMYV5XLh1KBJafeeRpau39rqrOGpJUGTUprBISOGNvc3lI7NZ8IBQ0lPU0e0SHe4O1t37Qkr8d1s2t7Apu27myv6TTtiKviwst/Zzk2k6WlGQU4WhblZDM/NYuKoYQzPyeLIkryElF1NQxG1eXs9FVW1vPX3lnBoesRmblbQpNR01jB1bD4jhmUnucQifWtP414272horrybKvimo/Sa7fseue9pZ2Th7Mw0CnMHMTys2AtzsyiImR4e8yrMHcSwwRm9flWgrhqSTrk773+0vVV/w7IPttLQGPx9jMzLbjlrGJPPESV55GTphFJSR1MzTEslvpuauno272h9lN505L5lZwPtVY/DsjMoHBJU7M1H7kNaKvWCmAq+MHcQg7PS+3Zn41AfgXTKzDioeAgHFQ/h00eVAMF/nKUfbKXi7y3h8KfFG4Dg1LWpSWlq2KT08eIhpKlJSfqAu7Nt956wbb0+fnNMmyP3HfWdN8MU5GYy8cBhLUfnQ1pX9E0Vf+YAuxpPZwTSLTV1u1lUVUvF34OO6EWVtWzdFQyHMWRQBlNK8lr1NxwwVE1K0rnGvR7/yLwupjkmpiN184765rPVtpqaYQpyMxmeO2ifppe2zTHDsjMjcQCjpiFJmL17nfdrtrc6a1j2wdbmttLR+YNbBcPkUXn94jRZEmtXQ+M+7ec1zUftrdvWu9IM01KJD2o5Os8J54VNMgU5wRG8mizjUxBIn9rV0MiS9VuaO6IrKmup2hw8rzk9zTjswJarlKaOzeegIjUp9WexzTAtR+mxFXtDcwXfVOlv77AZJrNVx2jbI/fCmDb2gtyB1wyTLAoCSbrqbbtZ1ObGt23hCKtDszM4siS/1ZlD0ZBBSS7xwNXUDBPbft72evXYjtTN2xua70Npa1BGWkz7+SCG54SV+pD4zTFRaYbpjxQE0u/s3eus/qiu1VnD8g3baAyblEoKBrc6azh8VB7ZmWpSimdXQ+M+NyJtalOpb97eQE141F7bQTPM0OyMOG3q7bSzD8licGa6Bj9MEQoCSQk76xtZvH5Lq/6GdbVBk1JGmjFx5LBWZw3jC3MH3NGlu1O3e09LJR7nRqTNO2KaZerab4ZJM5or7ab286aKfXhOJsOHtG6Oyc/JIitDzTADlYJAUtbGbbtaBcPbVVuoC5uUhmVncGTM5atHluRT2M+alBr3OrU74nWatn/k3lkzTOsbkQYxPGxjbzpKH54bdKTmDVYzjLRQEMiA0bjXea+6rvny1YrKWlZs2ErTDZ1jh+e0OmuYNHJYrzYp7d7T2OrIPP7ljk3jxjSweUd9h80wbS9nLIip4Ns2x+RkqRlGek5BIAPajvo9vFO1pdVd0R9s2QVAZroxqalJaWww2N64whzMrLkZJrb9PN6NSLEdqXXtPEI0zaAgp3X7eexYMU3NME1NNAVqhpE+piCQyPlw666YjujNvF21pfnO0rzBmQzOTGSOw4AAAAf/SURBVGfT9vp2m2Gymq6GiXsjUpvmmFw1w0j/pyEmJHJGDMtm+uQDmT75QCBoUlq5cRsVf69lUdUW9jTu3edGpNjmGDXDSJQoCCQSghvZhnHYgcOYdUyySyPSv6iRUkQk4hIaBGY23cxWmNkqM7uxg/X+wczczOK2X4mISOIkLAjMLB24B5gBTAIuMbNJcdYbClwDvJ6osoiISPsSeUZwDLDK3Ve7ez0wD7ggznrfBb4P7EpgWUREpB2JDILRQGXM+6pwXjMzOwoY4+5PdrQhM5ttZuVmVl5dXd37JRURibCkdRabWRpwOzCns3Xd/X53L3P3suLi4sQXTkQkQhIZBOuAMTHvS8J5TYYCk4EXzGwNcBwwXx3GIiJ9K5FB8AYwwczGm1kWMAuY37TQ3be4e5G7j3P3ccBrwEx3123DIiJ9KGE3lLn7HjO7EngKSAcedPclZnYrUO7u8zveQnwLFy78yMzW9mZZ21EEfNQH35MMA3XftF+pZ6DuW3/cr4+1tyDlxhrqK2ZW3t64HKluoO6b9iv1DNR9S7X90p3FIiIRpyAQEYk4BUH77k92ARJooO6b9iv1DNR9S6n9Uh+BiEjE6YxARCTiFASAmT1oZhvNbHHMvOFm9rSZrQx/FiSzjD1hZmPM7HkzW2pmS8zsmnB+Su+bmWWb2d/MbFG4X98J5483s9fD0W4fCe9fSUlmlm5mb5nZE+H7lN83M1tjZu+YWYWZlYfzUvpvEcDM8s3sN2a23MyWmdnxqbZfCoLAQ8D0NvNuBJ519wnAs+H7VLMHmOPukwju3L4iHAE21fdtN3C6ux8JlALTzew4gsEL73D3jwObgcuTWMb9dQ2wLOb9QNm309y9NObSylT/WwS4C/izux8GHEnw75Za++XuegX9JOOAxTHvVwAjw+mRwIpkl7EX9vFx4MyBtG9ADvAmcCzBDTwZ4fzjgaeSXb4e7lMJQeVxOvAEYANh34A1QFGbeSn9twjkAe8T9rem6n7pjKB9I9z9g3B6AzAimYXZX2Y2DphK8NyHlN+3sOmkAtgIPA28B9S6+55wlX1Gu00hdwLfAPaG7wsZGPvmwAIzW2hms8N5qf63OB6oBv43bMp7wMxySbH9UhB0gQexnrKXV5nZEOAx4Fp33xq7LFX3zd0b3b2U4Oj5GOCwJBepV5jZecBGd1+Y7LIkwEnufhTBw6quMLNTYhem6N9iBnAUcK+7TwW206YZKBX2S0HQvg/NbCRA+HNjksvTI2aWSRAC/+fuvw1nD4h9A3D3WuB5guaSfDNrGj+r7Wi3qeJEYGY4Iu88guahuxgA++bu68KfG4HfEQR4qv8tVgFV7t70hMXfEARDSu2XgqB984FLw+lLCdrXU4qZGfA/wDJ3vz1mUUrvm5kVm1l+OD2YoN9jGUEgXBSulnL7BeDuN7l7iQcj8s4CnnP3z5Li+2ZmueFjaQmbTs4CFpPif4vuvgGoNLNDw1lnAEtJsf3SDWWAmT0MTCMYMfBD4FvA74FHgbHAWuBid9+UrDL2hJmdBLwMvENLe/O/EfQTpOy+mdkU4GcEo9qmAY+6+61mdhDBUfRw4C3gc+6+O3kl3T9mNg34urufl+r7Fpb/d+HbDOBX7v49Myskhf8WAcysFHgAyAJWA5cR/l2SIvulIBARiTg1DYmIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMQpCCTlmVldN9adZmYn7Md35ZvZ1zpY3hiOrtn0GtfN7V8YDgwo0mcUBBI104AeBwGQD7QbBMBOD0bXbHqt6eb2LwS6FQQxdxyL9IjuI5CUZ2Z17j6kzbzzgZsJbvKpAT4LDAZeAxoJBgq7ClgO3Edw4w8E4zG9YmbfDucdFP68093vNrN5wAUEo0s+7e43dFSWcJynx4ECIBO42d0fD5d9Afg6wTg0bwP3Eow2uiV8/QMwNCxfDsHAel9y981m9gJQAZwEPAz8neBGyEZgi7u3GsdHpCMKAkl57QRBAcGInW5m/wxMdPc5YQVf5+4/CNf7FfATd/+LmY0lGN55YrjeWcBpBJXxCuBAglE/n3D3ye2UpZHgTm4Ihif+RyDH3beaWRFBEE0gOOr/HXCCu39kZsPdfZOZPRRu/zfh9t4GrnL3F83sVmCYu18bBsFSd/9auN47wHR3X2dm+eEYTCJdolNKGahKgEfCAb+yCCrleD4JTAqGZQJgWHgUD/BkOIzDbjPbSNeGEt4ZjooKNA/695/hSJt7CYJkBMFgcr92948A4g0/YGZ5QL67vxjO+hnw65hVHomZfgV4yMweBX6LSDcoCGSg+hFwu7vPD8fs+XY766UBx7n7rtiZYTDEjuXTSM/+v3wWKAaOdveGcFTR7B5sJ57tTRPu/hUzOxY4F1hoZke7e00vfY8McOosloEqj5ahmi+Nmb+NoKmnyQKCvgKgeQCxjrT9fFfKsTEMgdOAj4XznwP+MRx0DTMb3nb77r4F2GxmJ4fLPg+8SBxmdrC7v+7u3yTo/xjTjTJKxCkIZCDIMbOqmNf1BGcAvzazhQSPeWzyB+BT4aWdJwNXA2Vm9raZLQW+0tEXhUfZr5jZYjOb24Wy/V+4/XeALxB0TuPuS4DvAS+a2SKgaZjwecAN4dOuDiYIsblhX0EpcGs73zPXggfDLwZeBRZ1oWwigDqLRUQiT2cEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOL+PyJqidoK3NbvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fpjg-9i9tkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7cdaec-965f-459d-8d82-0251c90c2a17"
      },
      "source": [
        "#8,16,32,64\n",
        "np.argmin(rmse_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0ZW700lOk-u",
        "outputId": "b1dc22a3-9650-49f4-cba4-aeb799b799be"
      },
      "source": [
        "np.argmin(rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYTtH0_pl6sj"
      },
      "source": [
        "## Evaluating Other Models\n",
        "\n",
        "When evaluating models, it's important to compare to some reasonable baselines. \n",
        "\n",
        "Fortunately, Spotlight's `rmse_score()` method can be used to evaluate any Python object that adheres to the specification of the `predict()` function. For instance, we can make a baseline \"static\" scoring model, which returns the same scores for each user. This set of scores is passed as numpy array in the constructor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Xd1X4TX2Tq"
      },
      "source": [
        "class StaticModel:\n",
        "  \n",
        "  def __init__(self, staticscores):\n",
        "    self.numitems = len(staticscores)\n",
        "    self.staticscores = staticscores\n",
        "  \n",
        "  #uids are the user(s) we are requesting recommendations for;\n",
        "  #returns an array of scores, one for each item\n",
        "  #the array is duplicated for each user requested\n",
        "  def predict(self, uids, iids=None):\n",
        "    #this model returns all zeros, regardless of userid\n",
        "    \n",
        "    #we respond to one or more uids\n",
        "    uids = [uids] if isinstance(uids, int) else uids\n",
        "\n",
        "    #if iids is specificed, we filter predicts for those userids\n",
        "    iids = np.arange(self.numitems) if iids is None else iids\n",
        "    return [self.staticscores[iids] for u in uids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhl_7mUxmdlv"
      },
      "source": [
        "For instance, we can make a static baseline that just returns 0 for every item, regardless of the user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3FVJWJzYhoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59a3051-0d56-4df3-85ac-2d443374453c"
      },
      "source": [
        "mydummymodel = StaticModel(np.zeros(num_items))\n",
        "\n",
        "print(\"Asking for 2 users, one item: \" + str(mydummymodel.predict([0,1],0)))\n",
        "print(\"Asking for one item: \" + str(mydummymodel.predict(0,0)))\n",
        "print(\"Asking for two items: \" + str(mydummymodel.predict(0,[0,1])))\n",
        "print(\"RMSE of our dummy model: %f\" % rmse_score(mydummymodel, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Asking for 2 users, one item: [0.0, 0.0]\n",
            "Asking for one item: [0.0]\n",
            "Asking for two items: [array([0., 0.])]\n",
            "RMSE of our dummy model: 3.642758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSnTtOzAoA2l"
      },
      "source": [
        "## Task 6. Popularity-based Recommenders\n",
        "\n",
        "This task asks you to implement other baseline recommenders.\n",
        "\n",
        "**Using ratings_df**, create three new instances of StaticModel as baselines:\n",
        "\n",
        "(a). the number of ratings for each item - you must linearly normalise this to be in the range 0-5.\n",
        "\n",
        "(b). the number of 5 scores received by an item - you must linearly normalise this to be in the range 0-5.\n",
        "\n",
        "(c). the average rating value for each item (no need to normalise - scores are already 0-5)\n",
        "\n",
        "Evaluate your baseline models in terms of RMSE, as well as providing their scores for particular iids, as requested in the quiz.\n",
        "\n",
        "Hints:\n",
        " - You may find iterating over a dataframe using iterrows() useful - e.g. see  https://stackoverflow.com/a/16476974\n",
        " - Order is VERY IMPORTANT. Think carefully about the assumed order that predict() returns item scores for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpH330T9rzXd",
        "outputId": "b60ed1b4-4d1b-4950-f2de-938d4e9b961b"
      },
      "source": [
        "#a\n",
        "temp = np.zeros(num_items)\n",
        "for i, row in ratings_df.groupby(by=['movieId']).count().iterrows():\n",
        "  temp[iid_map[i]] = row['rating']\n",
        "ma = max(ratings)\n",
        "a = (temp/np.max(temp))*5\n",
        "\n",
        "print(\"model a RMSE: \",rmse_score(StaticModel(temp), test))\n",
        "print(\"model a \",StaticModel(a).predict(0,0))\n",
        "\n",
        "#b\n",
        "\n",
        "val = np.zeros(num_items)\n",
        "temp = ratings_df[(ratings_df[\"rating\"] == 5)].groupby(by=['movieId']).count()\n",
        "for i, row in temp.iterrows():\n",
        "  val[iid_map[i]] = row['rating']\n",
        "b = (val/np.max(val))*5\n",
        "\n",
        "print(\"model b RMSE: \",rmse_score(StaticModel(val), test))\n",
        "print(\"model b \",StaticModel(b).predict(0,0))\n",
        "\n",
        "#c\n",
        "val = np.zeros(num_items)\n",
        "\n",
        "for i, row in ratings_df.groupby(by=['movieId']).mean().iterrows():\n",
        "  val[iid_map[i]] = row['rating']\n",
        "c = (val/np.max(val))*5\n",
        "\n",
        "print(\"model c RMSE \",rmse_score(StaticModel(c), test))\n",
        "print(\"model c : \",StaticModel(c).predict(0,0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model a RMSE:  82.42443770737195\n",
            "model a  [3.2674772036474167]\n",
            "model b RMSE:  22.075079911833697\n",
            "model b  [1.5359477124183007]\n",
            "model c RMSE  0.8810745544813008\n",
            "model c :  [3.9209302325581397]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aCiYTWaeobQ"
      },
      "source": [
        "# Part C - Implicit Recommendation\n",
        "\n",
        "This part of the lab uses a music dataset from [Last.fm](https://www.last.fm/) -- a Spotify-like music streaming service -- that was obtained by a researcher at Pompeu Fabra University (Barcelona, Spain). The relevant citation is:\n",
        "\n",
        "```\n",
        "  @book{Celma:Springer2010,\n",
        "      \tauthor = {Celma, O.},\n",
        "      \ttitle = {{Music Recommendation and Discovery in the Long Tail}},\n",
        "       \tpublisher = {Springer},\n",
        "       \tyear = {2010}\n",
        "      }\n",
        " ```\n",
        "\n",
        "You can have more information about the dataset at [this link](http://ocelma.net/MusicRecommendationDataset/lastfm-1K.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsDavoa3qC64"
      },
      "source": [
        "## Dataset preparation\n",
        "\n",
        "This dataset is 600MB copmressed, and 2.4GB uncompressed. It takes 30 seconds to download on Colab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-drWmULel_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b868ae05-4d93-42eb-c0da-0e61983bae95"
      },
      "source": [
        "!rm -rf lastfm-dataset-1K.tar.gz\n",
        "!curl -o \"lastfm-dataset-1K.tar.gz\" \"http://www.dcs.gla.ac.uk/~craigm/recsysH/lastfm-dataset-1K.tar.gz\"\n",
        "#backup location\n",
        "#!curl -o \"lastfm-dataset-1K.tar.gz\" http://macavaney.us/misc/lastfm-dataset-1K.tar.gz\n",
        "!tar -zxvf lastfm-dataset-1K.tar.gz\n",
        "!ls -lh lastfm-dataset-1K/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  641M  100  641M    0     0  56.5M      0  0:00:11  0:00:11 --:--:-- 73.4M\n",
            "lastfm-dataset-1K/\n",
            "lastfm-dataset-1K/userid-profile.tsv\n",
            "lastfm-dataset-1K/README.txt\n",
            "lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv\n",
            "total 2.4G\n",
            "-rw-r--r-- 1 1002 1002 2.2K Mar 23  2010 README.txt\n",
            "-rw-r--r-- 1 1002 1002  37K Dec 30  2009 userid-profile.tsv\n",
            "-rw-r--r-- 1 1002 1002 2.4G Mar  4  2010 userid-timestamp-artid-artname-traid-traname.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcxILh_-h773"
      },
      "source": [
        "listens_df = pd.read_csv(\"lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv\",  names=['user', 'timestamp', 'artistid', 'artist', 'trackid', 'trackname'], header=None, sep='\\t')\n",
        "\n",
        "#Some tracks dont seem to have artists or track names, so lets drop them for simplicity.\n",
        "listens_df = listens_df[listens_df.artist.notnull()]\n",
        "listens_df = listens_df[listens_df.trackname.notnull()]\n",
        "\n",
        "#the dataframe is VERY big (19M interactions), so lets just work with a small sample of it (this will mean that effectiveness will be lower, but learning will be MUCH faster).\n",
        "listens_df = listens_df.sample(n=200000, random_state=np.random.RandomState(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZSwFnZSgrNU"
      },
      "source": [
        "\n",
        "Let's look at the dataset. Note that the we don't have any explicit ratings by the users. We just know what they interacted with (and when). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAP3dPt-4KMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "02a4a7c4-4468-4ab4-9660-583c40713eb1"
      },
      "source": [
        "listens_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>artistid</th>\n",
              "      <th>artist</th>\n",
              "      <th>trackid</th>\n",
              "      <th>trackname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11087179</th>\n",
              "      <td>user_000593</td>\n",
              "      <td>2007-05-14T18:49:03Z</td>\n",
              "      <td>ad996aef-cc1c-42ac-af5c-619c370f4b8a</td>\n",
              "      <td>Emerson, Lake &amp; Palmer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Three Fates (Clotho/Lachesis/Atropos)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1911790</th>\n",
              "      <td>user_000093</td>\n",
              "      <td>2008-08-18T22:04:59Z</td>\n",
              "      <td>8c538f11-c141-4588-8ecb-931083524186</td>\n",
              "      <td>Bloc Party</td>\n",
              "      <td>315a301e-e764-4adf-91c6-e90a22320106</td>\n",
              "      <td>Positive Tension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099786</th>\n",
              "      <td>user_000594</td>\n",
              "      <td>2008-04-06T10:57:45Z</td>\n",
              "      <td>65f4f0c5-ef9e-490c-aee3-909e7ae6b2ab</td>\n",
              "      <td>Metallica</td>\n",
              "      <td>683c89fe-2be8-4ed2-8e58-68b2343cb8d5</td>\n",
              "      <td>Through The Never</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12076983</th>\n",
              "      <td>user_000651</td>\n",
              "      <td>2008-05-10T07:14:45Z</td>\n",
              "      <td>3ca09fae-fdee-4771-bab9-244708515a98</td>\n",
              "      <td>Omarion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ice Box [Orangefuzzz Weather Advisory Radio Mix]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680461</th>\n",
              "      <td>user_000137</td>\n",
              "      <td>2009-03-11T23:17:22Z</td>\n",
              "      <td>af84ee9f-534a-4f7f-844b-188ba1c47e87</td>\n",
              "      <td>Los Rodrguez</td>\n",
              "      <td>76b83f07-3763-4c17-8d24-28040d85354a</td>\n",
              "      <td>Dulce Condena</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 user  ...                                         trackname\n",
              "11087179  user_000593  ...             Three Fates (Clotho/Lachesis/Atropos)\n",
              "1911790   user_000093  ...                                  Positive Tension\n",
              "11099786  user_000594  ...                                 Through The Never\n",
              "12076983  user_000651  ...  Ice Box [Orangefuzzz Weather Advisory Radio Mix]\n",
              "2680461   user_000137  ...                                     Dulce Condena\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLGzG9Rig3E6"
      },
      "source": [
        "## An implicit recommendation approach\n",
        "\n",
        "Let's move away from explicit recommendation to implicit.\n",
        "\n",
        "We will continue using the [Spotlight](https://github.com/maciejkula/spotlight/) toolkit for our recommender. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U03zZ6CH---1"
      },
      "source": [
        "We can construct [Interaction](https://maciejkula.github.io/spotlight/interactions.html) objects for Spotlight in the same way as before. The only difference is that this time we do not record the user's ratings.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcRhNWXzg7LT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc780d21-c1ee-455b-8167-3571ec7127f0"
      },
      "source": [
        "from collections import defaultdict\n",
        "from itertools import count\n",
        "\n",
        "#we cant trust the musicbrainz ids to exist, so lets build items ids based on artist & trackname attributes\n",
        "LFMiid_map = defaultdict(count().__next__)\n",
        "LFMiids = np.array([LFMiid_map[artist+\"/\"+trackname] for artist,trackname in listens_df[[\"artist\",\"trackname\"]].values ], dtype=np.int32)\n",
        "\n",
        "LFMuid_map = defaultdict(count().__next__)\n",
        "LFMuids = np.array([LFMuid_map[uid] for uid in listens_df[\"user\"].values ], dtype=np.int32)\n",
        "#freeze uid_map and iid_map so no more mapping are created\n",
        "LFMuid_map.default_factory = None\n",
        "LFMiid_map.default_factory = None\n",
        "\n",
        "LFMuid_rev_map = {v: k for k, v in LFMuid_map.items()}\n",
        "LFMiid_rev_map = {v: k for k, v in LFMiid_map.items()}\n",
        "\n",
        "from spotlight.interactions import Interactions\n",
        "from spotlight.cross_validation import random_train_test_split\n",
        "\n",
        "#NB: we will set num_users and num_items here - its a good practice.\n",
        "imp_dataset = Interactions(user_ids=LFMuids, item_ids=LFMiids, num_users=len(LFMuid_map), num_items=len(LFMiid_map))\n",
        "#we could add the timestamps here if we were doing sequence recommendation\n",
        "\n",
        "#what have we got.\n",
        "print(imp_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Interactions dataset (973 users x 125076 items x 200000 interactions)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22dmr7JKqUnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3871470b-b124-4698-9cb1-24c16cf35987"
      },
      "source": [
        "from spotlight.cross_validation import random_train_test_split\n",
        "\n",
        "itrain, itest = random_train_test_split(imp_dataset, random_state=np.random.RandomState(SEED))\n",
        "print(itrain)\n",
        "print(itest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Interactions dataset (973 users x 125076 items x 160000 interactions)>\n",
            "<Interactions dataset (973 users x 125076 items x 40000 interactions)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFQazPPxhG2_"
      },
      "source": [
        "Let's run Spotlight's impllicit Matrix Factorisation on this dataset. Here, we use a *pointwise* loss, which just tries to predict whether the user will like the item or not. It does not use the BPR loss function (more on that later).\n",
        "\n",
        "**Warning**: this dataset is difficult for the learner - this *will* take a few minutes to learn... Use the time to read-on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co3ZwYgkhKvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b11b29-ec1c-4783-f991-20b7c80ea4b6"
      },
      "source": [
        "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
        "import time  \n",
        "\n",
        "imodel = ImplicitFactorizationModel(n_iter=5, \n",
        "                                    embedding_dim=32, #this is Spotlight default\n",
        "                                    use_cuda=False,\n",
        "                                    random_state=np.random.RandomState(SEED) # ensure results are repeatable\n",
        ")\n",
        "current = time.time()\n",
        "\n",
        "imodel.fit(itrain, verbose=True)\n",
        "end = time.time()\n",
        "diff = end - current\n",
        "print(\"Training took %d seconds\" % (diff))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: loss 0.9663112482070922\n",
            "Epoch 1: loss 0.4953250741481781\n",
            "Epoch 2: loss 0.19036928775310516\n",
            "Epoch 3: loss 0.11518941127061844\n",
            "Epoch 4: loss 0.08347187245488166\n",
            "Training took 98 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zso4C5wehLog"
      },
      "source": [
        "Again, we can look at the predictions. We make a prediction (a score ) for ALL items for user uid 0. Note that the scores vary in magnitude - indeed, we're not predicting a rating, we just need to have scores in order to rank the items in descending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR_qbWXEhUDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23fb332d-3375-4180-83c9-3fe96fa49b5b"
      },
      "source": [
        "print(imodel.predict(0))\n",
        "print(len(imodel.predict(0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ -4.7575493   5.261615   -9.297658  ...  -9.027849  -11.658044\n",
            " -13.501964 ]\n",
            "125076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyZ3PyAxhdDF"
      },
      "source": [
        "Now that we have the scores of all items for a given user, we need to identify the top-scored ones, i.e. those that we would present to the user. \n",
        "\n",
        "## Task 7. Track Analysis\n",
        "\n",
        "Write a function `tracksForUser(user)` to identify the artist name & track of the top K (e.g. K=4) items based on their score for a given user index index (i.e. 0.. 964). What are the top scored 10 tracks recommended for user uid 4?\n",
        "\n",
        "Hints: \n",
        "\n",
        " \n",
        " - I also found [`np.argwhere()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argwhere.html) to be useful. It results only the positions of an array that are True. For instance:\n",
        "```\n",
        ">>> np.argwhere([True, False])\n",
        "array([[0]])\n",
        "```\n",
        " Alternatively, you can sort and then slice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V93_Bxw3MG1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df71eb5-804c-435e-d297-9ddef0eb6951"
      },
      "source": [
        "#your solution here\n",
        "def tracksForUser(user):\n",
        "  scores = imodel.predict(user)\n",
        "\n",
        "  highest = rankdata(scores).argsort()[::-1]\n",
        "  for i in range(0,10):\n",
        "    print(i+1,')TrackId', highest[i],  'Track : ', LFMiid_rev_map.get(highest[i]), ', Score : ', scores[highest[i]])\n",
        "   \n",
        "tracksForUser(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 )TrackId 23827 Track :  Evanescence/Sweet Sacrifice , Score :  13.124241\n",
            "2 )TrackId 13482 Track :  Mgmt/Kids , Score :  12.674836\n",
            "3 )TrackId 7010 Track :  The Killers/Bones , Score :  12.663473\n",
            "4 )TrackId 22003 Track :  Nelly Furtado/Say It Right , Score :  12.464149\n",
            "5 )TrackId 8037 Track :  Kings Of Leon/Use Somebody , Score :  12.436815\n",
            "6 )TrackId 5248 Track :  Amy Winehouse/Back To Black , Score :  12.173226\n",
            "7 )TrackId 24046 Track :  Red Hot Chili Peppers/The Zephyr Song , Score :  11.530579\n",
            "8 )TrackId 504 Track :  Radiohead/Fake Plastic Trees , Score :  10.859598\n",
            "9 )TrackId 7311 Track :  Incubus/Drive , Score :  10.710463\n",
            "10 )TrackId 7048 Track :  Him/The Funeral Of Hearts , Score :  10.703401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWFSAuQ40p2Y"
      },
      "source": [
        "## Task 8. Artist Analysis\n",
        "\n",
        "Look at the artists actually listened to by uid 4, and compare/contrast with the predictions of the recommender. It's useful to examine how many times each artist was listened to.\n",
        "\n",
        "Hints: \n",
        " - use a groupby on a suitable subset of the listens_df dataframe. \n",
        " - Sort by descending frequency of listen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2wFfGfcMJcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b78697ba-9a68-4d73-ac2b-ed42f98e1ecc"
      },
      "source": [
        "#your solution here\n",
        "\n",
        "a = LFMuid_rev_map.get(4)\n",
        "uid_4 = listens_df[listens_df['user'] == a]\n",
        "b = uid_4.groupby('artist')['artistid'].count().reset_index().rename(columns={\"artist\" : \"artist\", \"artistid\" : \"frequency\"})\n",
        "b.sort_values('frequency', ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>Soda Stereo</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Gustavo Cerati</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>Radiohead</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Lucybell</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>Silvio Rodrguez</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Fito Pez, Gustavo Cerati Y Charly Garca</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Inti Illimani\\Inti+Quila</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>La Ley Y Amaral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02 2 X 4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01 Ain'T My Bitch</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>146 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        artist  frequency\n",
              "119                                Soda Stereo         39\n",
              "55                              Gustavo Cerati         36\n",
              "104                                  Radiohead         31\n",
              "82                                    Lucybell         27\n",
              "114                           Silvio Rodrguez         16\n",
              "..                                         ...        ...\n",
              "45   Fito Pez, Gustavo Cerati Y Charly Garca          0\n",
              "59                    Inti Illimani\\Inti+Quila          0\n",
              "68                             La Ley Y Amaral          0\n",
              "1                                     02 2 X 4          0\n",
              "0                            01 Ain'T My Bitch          0\n",
              "\n",
              "[146 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2FWymqQRxKj"
      },
      "source": [
        "I observed that uid 4 listened frequently to \"Radiohead\" (rank 3), while a Radiohead song was among the top 10 ranked songs in our predicted model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmTNae6Romuk"
      },
      "source": [
        "## Evaluating an implicit recommender\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Q2TTpZuHON"
      },
      "source": [
        "We can examine the MRR of the implicit model we have learned. We pass it the test set (which contains knowledge of what the user *actually* clicked), as our ground truth. \n",
        "\n",
        "In the second variant, we also pass the training data. Give a look at the  implementation of [mrr_score()](https://github.com/cmacdonald/spotlight/blob/master/spotlight/evaluation.py#L8) to understand what it is doing, and why.\n",
        "\n",
        "**Questions for you to consider**\n",
        " - Why is the second score lower? \n",
        " - Would this be the same for all recommendation settings? \n",
        " - In the implementation, why are the scores negated, why do we use [rankdata()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html)?\n",
        " \n",
        "We will use the first variant for this Lab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLV71LSjt-k2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0730d9-be0d-43da-c97a-dac27b9c92d6"
      },
      "source": [
        "from spotlight.evaluation import mrr_score\n",
        "\n",
        "#evaluate on this dataset takes approx 1 minute\n",
        "!date\n",
        "print(mrr_score(imodel, itest).mean())\n",
        "!date\n",
        "print(mrr_score(imodel, itest,  train=itrain).mean())\n",
        "!date\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug  4 14:58:33 UTC 2021\n",
            "0.03720125940064275\n",
            "Wed Aug  4 14:59:00 UTC 2021\n",
            "0.008104536778740273\n",
            "Wed Aug  4 14:59:27 UTC 2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjM_kZNtAE2k"
      },
      "source": [
        "How to interpret an MRR score - we know it has a range [0,1] with 1 being best. 1 means, on average across all users, we make a relevant prediction at rank 1; 0.5 means, on average, at rank 2. This is a very rough rule-of-thumb - MRR isn't a linear measure, so  a few poor predictions affect the average more than a few good ones.\n",
        "\n",
        "\n",
        "You can now answer all questions for Task 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL2jRiGF2uLb"
      },
      "source": [
        "## Task 9. Listens and Recommendations\n",
        "\n",
        "*   Pick the user with the lowest uid that has RR=1 (you should not specify `train=` when making this choice). How many listens (ie. how many times they have listened to any song) did they have in the training dataset?\n",
        "*   Similarly, pick the user with the lowest uid that had the lowest RR. How many listens did they have in the training dataset?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6H0l1S6nNcd"
      },
      "source": [
        "#solution goes here.\n",
        "a = mrr_score(imodel, itest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVO7fM1qtkrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4faf6ab4-47e8-4e0f-ba25-0378e3882b75"
      },
      "source": [
        "index_1 = np.argwhere(a == 1)\n",
        "first_uid = index_1[0][0]\n",
        "first_user = LFMuid_rev_map.get(first_uid)\n",
        "print('1. (first user,lowest uid) :',first_uid,first_user)\n",
        "print('listens_1 :', len(itrain.item_ids[itrain.user_ids == first_uid]))\n",
        "\n",
        "index_0 = np.argwhere(a == 0)\n",
        "zero_uid = index_0[0][0]\n",
        "zero_user = LFMuid_rev_map.get(zero_uid)\n",
        "print('0. (first user,lowest uid) :',zero_uid,zero_user)\n",
        "print('listens_0 :', len(itrain.item_ids[itrain.user_ids == zero_uid]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. (first user,lowest uid) : 31 user_000833\n",
            "listens_1 : 757\n",
            "0. (first user,lowest uid) : 1 user_000093\n",
            "listens_0 : 355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0GehAVYkawF"
      },
      "source": [
        "Next, make a numpy array containing the number of listens for each uid in the LastFM dataset. Plot a histogram of the distribution - like in Exercise 1, use matplotlib's histogram functionality, the default number of bins and use log=True.\n",
        "Save the PNG for uploading to the quiz when prompted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqnn-cytkgEL",
        "outputId": "e658b50d-46a6-43d6-c7ff-c2dd3b848368"
      },
      "source": [
        "len(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "973"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opQHlQja175Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "6e597ddb-d3ad-4d33-c6a2-7d42f41b6261"
      },
      "source": [
        "ids = itrain.user_ids\n",
        "listens = []\n",
        "for i in range(0,len(a)):\n",
        "  listen = len(itrain.item_ids[itrain.user_ids == i])\n",
        "  listens.append(listen)\n",
        "i,j,k = plt.hist(listens, log = True, color = (0.5,0.1,0.5,0.6))\n",
        "plt.title('Distribution of listens')\n",
        "plt.xlabel('listens')\n",
        "plt.ylabel('users')\n",
        "plt.savefig('task9.png')\n",
        "plt.plot()\n",
        "print(i,j,k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[612. 187. 101.  32.  18.  10.   5.   4.   2.   2.] [   0.   146.3  292.6  438.9  585.2  731.5  877.8 1024.1 1170.4 1316.7\n",
            " 1463. ] <a list of 10 Patch objects>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anEhZSz9nPZt"
      },
      "source": [
        "Next, make a numpy array containing the number of listens for each uid in the LastFM dataset. Plot a histogram of the distribution - like in Exercise 1, use matplotlib's histogram functionality, the default number of bins and use `log=True`. \n",
        "\n",
        "Save the PNG for uploading to the quiz when prompted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKgL26EU7g2t"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kjpISm3nwAy"
      },
      "source": [
        "Many users have very few listens. Lets set 20 listens as a threshold.\n",
        "\n",
        "Lets define users with < 20 listens as cold-start users.\n",
        "How many cold-start users are there?\n",
        "What is the MRR for ONLY these users, versus \"normal\" with 20 or more listens.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNvCe_cWAbcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972c4fb6-9b2d-4570-a379-b4a1347ef03a"
      },
      "source": [
        "\n",
        "less_20 = []\n",
        "mrr_less_20 = {}\n",
        "mrr_more_20 = {}\n",
        "mrr_tot_less_20 = 0\n",
        "mrr_tot_more_20 = 0\n",
        "\n",
        "for i in range(len(listens)):\n",
        "  if listens[i] < 20:\n",
        "    less_20.append(i)\n",
        "\n",
        "for i in range(len(a)):\n",
        "  if i in less_20:\n",
        "    mrr_less_20[i] = a[i]\n",
        "  else:\n",
        "    mrr_more_20[i] = a[i]\n",
        "\n",
        "for i,j in mrr_less_20.items():\n",
        "  mrr_tot_less_20 += j\n",
        "\n",
        "for i,j in mrr_more_20.items():\n",
        "  mrr_tot_more_20 += j\n",
        "\n",
        "print(\"Cold-start users:\", len(less_20))\n",
        "print(\"MRR for less than 20 listens users :\",(mrr_tot_less_20/len(less_20)) )\n",
        "print(\"MRR for normal listens users :\",(mrr_tot_more_20/len(mrr_more_20)) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cold-start users: 162\n",
            "MRR for less than 20 listens users : 0.0024250440917107582\n",
            "MRR for normal listens users : 0.044147926330417094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR_l43rFc7eo"
      },
      "source": [
        "## Task 10 - BPR\n",
        "\n",
        "Finally, let's compare the *pointwise* implicit factorisation model with *BPR*. BPR is a very key recommendation model in the literature, which is widely used today as a baseline in many research papers.\n",
        "\n",
        "Train an ImplicitFactorizationModel on the Last FM dataset (i.e. `itrain`) using identical settings as before, except adding `loss='bpr'`. Record the time taken to train, and the evaluate its effectiveness in terms of MRR. Do NOT use the `train=itrain` argument to `mrr_score()`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oiCB4PuMQ_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846aceaf-e457-48e3-ea4c-ecd6fd72b7f9"
      },
      "source": [
        "#solution goes here\n",
        "bpr_model = ImplicitFactorizationModel(n_iter=5, \n",
        "                                    embedding_dim=32, #this is Spotlight default\n",
        "                                    use_cuda=False,\n",
        "                                    random_state=np.random.RandomState(SEED), # ensure results are repeatable\n",
        "                                    loss='bpr'\n",
        ")\n",
        "current = time.time()\n",
        "\n",
        "bpr_model.fit(itrain, verbose=True)\n",
        "end = time.time()\n",
        "diff = end - current\n",
        "print(\"Training took %d seconds\" % (diff))\n",
        "\n",
        "!date\n",
        "print(mrr_score(bpr_model, itest).mean())\n",
        "!date"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: loss 0.47409722967147827\n",
            "Epoch 1: loss 0.14683696564435958\n",
            "Epoch 2: loss 0.024808155347406866\n",
            "Epoch 3: loss 0.014375435864552855\n",
            "Epoch 4: loss 0.011113877035304904\n",
            "Training took 101 seconds\n",
            "Wed Aug  4 15:02:17 UTC 2021\n",
            "0.05814735966328977\n",
            "Wed Aug  4 15:02:44 UTC 2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awTPM_BGcUc0"
      },
      "source": [
        "# End of Exercise\n",
        "\n",
        "As part of your submission, you should complete the Exercise 2 quiz on Moodle.\n",
        "You will need to upload your notebook, complete with the **results** of executing the code (including figures and plots)."
      ]
    }
  ]
}